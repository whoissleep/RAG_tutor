{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"–ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ –Ω–∞–ø–∏—Å–∞–Ω –ï–≥–æ—Ä–æ–º –∏–∑ AIKC <3. –°–µ–≥–æ–¥–Ω—è –º—ã —Ä–∞–∑–±–µ—Ä–µ–º —Å–∞–º—ã–π –ø—Ä–∏–º–∏—Ç–∏–≤–Ω—ã–π RAG. –î–ª—è –Ω–∞—á–∞–ª–∞, –Ω–∞–º –Ω—É–∂–Ω—ã –±–∏–±–ª–∏–æ—Ç–µ–∫–∏, —Å –∫–æ—Ç–æ—Ä—ã–º–∏ –Ω–∞–º –ø—Ä–∏–¥–µ—Ç—Å—è —Ä–∞–±–æ—Ç–∞—Ç—å.\n\ntg: @who_is_sleep\n\nAIKC: https://t.me/aiknowledgeclub","metadata":{}},{"cell_type":"code","source":"!pip install PyMuPDF\n!pip install scapy\n!pip install sentence-transformers\n!pip install bitsandbytes\n!pip install --upgrade transformers\n!pip install faiss-cpu\nimport numpy as np\nimport pandas as pd\nimport torch\nimport transformers\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nimport requests\nimport os\nimport fitz\nfrom tqdm.auto import tqdm\nfrom spacy.lang.en import English\nfrom sentence_transformers import SentenceTransformer, util","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:00:41.478293Z","iopub.execute_input":"2024-10-30T17:00:41.478634Z","iopub.status.idle":"2024-10-30T17:02:01.275211Z","shell.execute_reply.started":"2024-10-30T17:00:41.478596Z","shell.execute_reply":"2024-10-30T17:02:01.274381Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: PyMuPDF in /opt/conda/lib/python3.10/site-packages (1.24.13)\nRequirement already satisfied: scapy in /opt/conda/lib/python3.10/site-packages (2.6.0)\nRequirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (3.2.1)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.46.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.25.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.44.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: faiss-cpu in /opt/conda/lib/python3.10/site-packages (1.9.0)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /opt/conda/lib/python3.10/site-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from faiss-cpu) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->faiss-cpu) (3.1.2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"–ü—Ä–æ–≤–µ—Ä–∏–º –¥–æ—Å—Ç—É–ø —É CUDA. –î–ª—è —ç—Ç–æ–≥–æ –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è torch.","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:01.280133Z","iopub.execute_input":"2024-10-30T17:02:01.280405Z","iopub.status.idle":"2024-10-30T17:02:01.284961Z","shell.execute_reply.started":"2024-10-30T17:02:01.280374Z","shell.execute_reply":"2024-10-30T17:02:01.283898Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"–¢–µ–ø–µ—Ä—å –Ω–∞–º –Ω–∞–¥–æ –¥–æ—Å—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ. –í–æ–∑—å–º–µ–º, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Å—Ç–∞—Ç—å—é –ø—Ä–æ KAT(Kolmogorov Arnold Transformer), url: https://arxiv.org/abs/2409.10594","metadata":{}},{"cell_type":"code","source":"path = \"KAT.pdf\"\n\nif not os.path.exists(path):\n    print(f\"[INFO] We don't have this file, downloading...\")\n    \n    url = \"https://arxiv.org/pdf/2409.10594\"\n    \n    filename = path\n    \n    response = requests.get(url)\n    \n    if response.status_code == 200:\n        with open(filename, \"wb\") as file:\n            file.write(response.content)\n            print(f\"File downloaded as {filename}\")\n    else:\n        print(f\"Can't download. Status code: {respones.status_code}\")\nelse:\n    print(f\"File {path} is good!\")","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:01.286089Z","iopub.execute_input":"2024-10-30T17:02:01.286478Z","iopub.status.idle":"2024-10-30T17:02:01.304914Z","shell.execute_reply.started":"2024-10-30T17:02:01.286419Z","shell.execute_reply":"2024-10-30T17:02:01.304001Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"File KAT.pdf is good!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"–î–∞–ª–µ–µ, –Ω–∞–º –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –∏–∑ –Ω–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö DataFrame. –î–∞–≤–∞–π—Ç–µ —Å–¥–µ–ª–∞–µ–º —ç—Ç–æ.","metadata":{}},{"cell_type":"code","source":"def formatting_text(text: str) -> str:\n    return text.replace('\\n', ' ').strip()\n\ndef open_and_read_pdf(path_pdf: str) -> list[dict]:\n    pdf = fitz.open(path_pdf)\n    all_info_about_pdf = []\n    for number_of_page, page in tqdm(enumerate(pdf)):\n        text = formatting_text(page.get_text())\n        all_info_about_pdf.append({\n            \"page_number\": number_of_page + 1, # –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã\n            \"page_char_counts\": len(text), # –∫–æ–ª–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤\n            \"page_word_counts\": len(text.split(\" \")), # –∫–æ–ª–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤\n            \"page_sents_counts\": len(text.split(\". \")), # –∫–æ–ª–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n            \"page_token_counts(approximately)\": len(text) / 4, # –∫–æ–ª–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤, –ø–æ—á–∏—Ç–∞—Ç—å—å –ø—Ä–æ —ç—Ç–æ –º–æ–∂–Ω–æ —Ç—É—Ç: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\n            \"text\": text # —Ç–µ–∫—Å—Ç\n        })\n    return all_info_about_pdf\n\npdf = open_and_read_pdf(path_pdf=path)\n\npdf[:2]","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:01.307768Z","iopub.execute_input":"2024-10-30T17:02:01.308081Z","iopub.status.idle":"2024-10-30T17:02:01.511259Z","shell.execute_reply.started":"2024-10-30T17:02:01.308048Z","shell.execute_reply":"2024-10-30T17:02:01.510306Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20ce6e8076614169b3f4f7a05631f8c2"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[{'page_number': 1,\n  'page_char_counts': 3032,\n  'page_word_counts': 419,\n  'page_sents_counts': 33,\n  'page_token_counts(approximately)': 758.0,\n  'text': 'Kolmogorov‚ÄìArnold Transformer Xingyi Yang Xinchao Wang National University of Singapore xyang@u.nus.edu; xinchao@nus.edu.sg Input Emb. Norm Attention Norm MLP Transformer  Input Emb. Norm Attention Norm KAN ViT + KAN ViT KAT* DeiT ViT + KAN KAT Input Emb. Norm Attention Norm GR-KAN KAT(Ours) Figure 1: (Left) Architecture of standard transformer (e.g. ViT), ViT+KAN which substitutes the MLP with a KAN, and our KAT model. In KAT, the MLP layers in transformers are replaced with GR-KAN layers. (Right) Performance on the ImageNet dataset. KAT‚àóindicates that the model was initialized using a pre-trained ViT. Generally, KAT outperforms both the ViT and DeiT models. ViT+KAN performs poorly on ImageNet-level training. Abstract Transformers stand as the cornerstone of mordern deep learning. Traditionally, these models rely on multi-layer perceptron (MLP) layers to mix the information between channels. In this paper, we introduce the Kolmogorov‚ÄìArnold Transformer (KAT), a novel architecture that replaces MLP layers with Kolmogorov-Arnold Network (KAN) layers to enhance the expressiveness and performance of the model. Integrating KANs into transformers, however, is no easy feat, especially when scaled up. Specifically, we identify three key challenges: (C1) Base function. The standard B-spline function used in KANs is not optimized for parallel computing on modern hardware, resulting in slower inference speeds. (C2) Parameter and Computation Inefficiency. KAN requires a unique function for each input-output pair, making the computation extremely large. (C3) Weight initialization. The initialization of weights in KANs is particularly challenging due to their learnable activation functions, which are critical for achieving convergence in deep neural networks. To overcome the aforementioned challenges, we propose three key solutions: (S1) Rational basis. We replace B-spline functions with rational functions to improve compatibility with modern GPUs. By implementing this in CUDA, we achieve faster computations. (S2) Group KAN. We share the activation weights through a group of neurons, to reduce the computational load without sacrificing performance. (S3) Variance-preserving initialization. We carefully initialize the activation weights to make sure that the activation variance is maintained across layers. With these designs, KAT scales effectively and readily outperforms traditional MLP-based transformers. We demonstrate the advantages of KAT across various tasks, including image recognition, object detection, and semantic segmentation. It consistently enhances performance over the standard transformer architectures of different model sizes. Our code is openly available at https://github.com/Adamdad/kat. 1 Introduction Transformers have become the de facto architecture in deep learning, widely adopted in computer vision [DBK+21] and natural language processing [VSP+17]. At their core, transformers are built upon two fundamental components: attention 1 arXiv:2409.10594v1  [cs.LG]  16 Sep 2024'},\n {'page_number': 2,\n  'page_char_counts': 4781,\n  'page_word_counts': 652,\n  'page_sents_counts': 50,\n  'page_token_counts(approximately)': 1195.25,\n  'text': 'modules and multi-layer perceptrons (MLPs). Although significant research has focused on replacing the traditional attention mechanism with alternative operations [LLC+21, LMW+22, THK+21], these variants still lean heavily on MLPs. Surprisingly, there have been relatively few efforts [Sha20] aimed at enhancing MLPs themselves. Opening up the box, MLPs are composed of stacked linear layers coupled with non-linear activations. What makes it so popular is that, theoretically, they can approximate any function, assuming that there are enough neurons avail- able [HSW89]. However, despite their versatility, MLPs face limitations in modeling complex functions. For example, when using ReLU-like activation, a two-layer MLP may struggle to fit periodic functions. Moreover, employing gradient descent to train these networks often results in prolonged convergence times for high-frequency components [RBA+19, BGG+20, RJKK19]. These challenges have led researchers to explore alternative, perhaps more expressive architectures than MLPs. Recently, Kolmogorov-Arnold Networks (KANs) emerged as a powerful alternative. KANs are noted for their theoretical parameter efficiency, potentially requiring fewer parameters to model complex functions [LWV+24]. They are particularly suitable for mathematical or symbolic regression tasks [YYW24, BC24a, LMW+24]. The key to such success is the learnable base function in each input-output pair. Those functions are often parameterized by B-spline curves [UAE93, GR74]. This design allows KANs to approximate more intricate functions through a summation of spline bases. Given its potential, integrating KAN layers into transformers [VSP+17] becomes an exciting topic. Such integration may boost the expressiveness and efficiency of transformers, enhancing their competitiveness across a wide range of applications. Unfortunately, this ambition has been met with limited success. In particular, KANs have been reported to be ‚Äú10√ó slower than MLPs, given the same number of parameters‚Äù. Initial attempts to apply KANs to vision recognition tasks have yielded disappointing results. Even on a small scale, these studies have consistently fallen short of matching, let alone surpassing, the performance of traditional architectures. This lack of improvement is often attributed to the limited computational resources and ongoing scalability problems [Che24a, BTSP24, Che24a, Che24b]. In a preliminary experiment, we attempted to replace MLP layers in the Vision Transformer (ViT) with KAN layers. It creates a model, which we call ViT+KAN. However, as shown in Figure 1 (Right), this straightforward substitution led to significant challenges when performing ImageNet-scale training, resulting in poor performance. Scalability, therefore, remains a significant obstacle for KAN-based models. Motivation and Challenges. Through dedicated analysis, we have identified several key challenges that hinder the effectiveness of KANs in large-scale applications, ultimately limiting their scalability. ‚Ä¢ (C1) Base function. The standard B-spline functions in KANs are not ideal for parallel computing architectures typical of modern GPUs. B-splines require recursive computation, which significantly slows down even the most optimized implementations. ‚Ä¢ (C2) Parameter and Computation Inefficiency. Each unique input-output pair in a KAN requires a distinct set of parameters and base functions. This necessity causes an exponential growth in the number of parameters as the network‚Äôs hidden size increases, resulting in substantial computational overhead and scalability issues. ‚Ä¢ (C3) Weight initialization. The weight initialization in KANs is similar to that in MLPs, but it does not meet KANs‚Äô needs for convergence. This mismatch can lead to instability and degraded performance during the training process. Our Approach. In this paper, we introduce Kolmogorov‚ÄìArnold Transformer (KAT), which successfully integrates KANs into transformers for large-scale training scenarios such as ImageNet. Beyond simple replacement, We have developed three key innovations (S1-S3) to address these challenges (C1-C3) respectively. ‚Ä¢ (S1) Rational activation. We employ rational function as our base function and provide full CUDA implementation. It aligns better with modern GPU architectures, enhancing computational efficiency and compatibility. ‚Ä¢ (S2) Group KAN. We share function coefficients and base functions among groups of edges. This strategy reduces computational load significantly without sacrificing performance. ‚Ä¢ (S3) Variance-preserving initialization. We carefully initialize weights to maintain consistent variance in activations across the model‚Äôs layers. This ensures stability during training and improves the model‚Äôs learning dynamics. 2'}]"},"metadata":{}}]},{"cell_type":"markdown","source":"–ö—Ä—É—Ç–æ, —Ç–µ–ø–µ—Ä—å —É –Ω–∞—Å –µ—Å—Ç—å —Å–ª–æ–≤–∞—Ä—å, –≤ –∫–æ—Ç–æ—Ä–æ–º –º–Ω–æ–≥–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ–∫—Å—Ç–µ. NLP –∏–Ω–∂–µ–Ω–µ—Ä—ã –æ—á–µ–Ω—å –ª—é–±—è—Ç –±–æ–ª—å—à–æ–µ –∫–æ–ª–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ–∫—Å—Ç–µ!","metadata":{}},{"cell_type":"markdown","source":"–î–∞–≤–∞–π—Ç–µ —Ç–µ–ø–µ—Ä—å —Ä–∞–∑–æ–±—ä–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏. –î–ª—è –Ω–∞—á–∞–ª–∞, –Ω–∞–º –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –î–ª—è —ç—Ç–æ–≥–æ –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è sentenizer'–æ–º –æ—Ç spacy.","metadata":{}},{"cell_type":"code","source":"nlp = English()\n\nnlp.add_pipe(\"sentencizer\")\n\nfor item in tqdm(pdf):\n    item['sents'] = list(nlp(item['text']).sents)\n    \n    item['sents'] = [str(sent) for sent in item['sents']]\n    \n    item['page_sents_count_spacy'] = len(item['sents'])","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:01.512558Z","iopub.execute_input":"2024-10-30T17:02:01.512879Z","iopub.status.idle":"2024-10-30T17:02:02.072496Z","shell.execute_reply.started":"2024-10-30T17:02:01.512846Z","shell.execute_reply":"2024-10-30T17:02:02.071509Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d4f590d40d848439fc3a427b26e84b1"}},"metadata":{}}]},{"cell_type":"code","source":"pdf[12]","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:02.073727Z","iopub.execute_input":"2024-10-30T17:02:02.074046Z","iopub.status.idle":"2024-10-30T17:02:02.082693Z","shell.execute_reply.started":"2024-10-30T17:02:02.074014Z","shell.execute_reply":"2024-10-30T17:02:02.081777Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'page_number': 13,\n 'page_char_counts': 4100,\n 'page_word_counts': 556,\n 'page_sents_counts': 41,\n 'page_token_counts(approximately)': 1025.0,\n 'text': 'Visualization of Trained Functions An important aspect to examine is the behavior of the trained rational functions. As shown in Figure 7, we plot the functions for KAT-S with ùëî= 8 across all 12 layers. The results indicate that within each layer, the rational functions exhibit similar trends, while the functions across different layers tend to differ from one another. 6 Conclusion and Future Work In this work, we introduced the Kolmogorov‚ÄìArnold Transformer (KAT), a novel architecture that successfully integrates Kolmogorov-Arnold Networks (KANs) into transformers, addressing key challenges associated with large-scale training scenarios. Our proposed Group-Rational KAN (GR-KAN) variant, with its rational activation functions, group-based parameter sharing, and variance-preserving initialization, demonstrated significant improvements in computational efficiency and scalability. Through extensive experiments on vision tasks, including image recognition, object detection, and semantic segmentation, KAT outperformed traditional MLP-based transformers, achieving superior accuracy on ImageNet1K while maintaining comparable computational demands. Discussion. Our study highlights KAT‚Äôs potential as a good alternative to MLP-based transformers, especially in large-scale vision tasks. This integration introduces exciting opportunities for broad applications. For example, employing KAT architectures might help development of language models. However, KAT is not without its challenges. A primary concern is running speed. Even with the CUDA optimized code, the rational function is still slower than plain activation like ReLU and GELU. Another issue is the stability when using rational functions in neural networks. The higher order gradients for ùëéùëöand ùëèùëõcan become unstable because of their dependence on the input power. Integrating these functions into the backpropagation process could introduce complications. Additionally, it is important to acknowledge that our GR-KAN represents a hybrid model. On the one hand, GR-KAN is a KAN layer with shared edges and a rational base function. On the other hand, it can be interpret as MLP with a redesigned activation placed before the linear layer. It leverages the computational simplicity of MLPs but maintains some characteristics of KANs. However, GR-KAN is not a pure KAN model. Instead, it merges advantages from both systems to enhance overall functionality. Future Work. There are multiple directions of KAT for future research. One potential area of exploration is to find alter- native base functions to further improve computational efficiency and compatibility with emerging hardware architectures. Currently, rational functions serve as one option, but other possibilities exist. These include Fourier transformations [Noe24], Wavelet transforms [BC24b], and Gaussian radial bases [Li24]. Additionally, expanding the applicability of KAT to other domains beyond vision tasks, such as natural language processing or reinforcement learning, could unlock new opportunities for performance gains. Further research could also investigate hybrid models [YZL+22, YSZ+23], or adaptive mechanisms for dynamically selecting between KAN and MLP layers based on the complexity of the task, thereby optimizing resource utilization. Finally, addressing the remaining scalability challenges, particularly in terms of memory footprint and inference speed, will be crucial for deploying KAT in real-world applications at scale. Acknowledgement We would like to acknowledge that computational work involved in this research work is partially supported by NUS IT‚Äôs Research Computing group using grant numbers NUSREC-HPC-00001. We thank Weihao Yu, Qiuhong Shen and Runpeng yu for valuable discussions. References [Agh24] Alireza Afzal Aghaei. rkan: Rational kolmogorov-arnold networks. arXiv preprint arXiv:2406.14495, 2024. [BC24a] Zavareh Bozorgasl and Hao Chen. Wav-kan: Wavelet kolmogorov-arnold networks. arXiv preprint arXiv:2405.12832, 2024. [BC24b] Zavareh Bozorgasl and Hao Chen. Wav-kan: Wavelet kolmogorov-arnold networks, 2024. 13',\n 'sents': ['Visualization of Trained Functions An important aspect to examine is the behavior of the trained rational functions.',\n  'As shown in Figure 7, we plot the functions for KAT-S with ùëî= 8 across all 12 layers.',\n  'The results indicate that within each layer, the rational functions exhibit similar trends, while the functions across different layers tend to differ from one another.',\n  '6 Conclusion and Future Work In this work, we introduced the Kolmogorov‚ÄìArnold Transformer (KAT), a novel architecture that successfully integrates Kolmogorov-Arnold Networks (KANs) into transformers, addressing key challenges associated with large-scale training scenarios.',\n  'Our proposed Group-Rational KAN (GR-KAN) variant, with its rational activation functions, group-based parameter sharing, and variance-preserving initialization, demonstrated significant improvements in computational efficiency and scalability.',\n  'Through extensive experiments on vision tasks, including image recognition, object detection, and semantic segmentation, KAT outperformed traditional MLP-based transformers, achieving superior accuracy on ImageNet1K while maintaining comparable computational demands.',\n  'Discussion.',\n  'Our study highlights KAT‚Äôs potential as a good alternative to MLP-based transformers, especially in large-scale vision tasks.',\n  'This integration introduces exciting opportunities for broad applications.',\n  'For example, employing KAT architectures might help development of language models.',\n  'However, KAT is not without its challenges.',\n  'A primary concern is running speed.',\n  'Even with the CUDA optimized code, the rational function is still slower than plain activation like ReLU and GELU.',\n  'Another issue is the stability when using rational functions in neural networks.',\n  'The higher order gradients for ùëéùëöand ùëèùëõcan become unstable because of their dependence on the input power.',\n  'Integrating these functions into the backpropagation process could introduce complications.',\n  'Additionally, it is important to acknowledge that our GR-KAN represents a hybrid model.',\n  'On the one hand, GR-KAN is a KAN layer with shared edges and a rational base function.',\n  'On the other hand, it can be interpret as MLP with a redesigned activation placed before the linear layer.',\n  'It leverages the computational simplicity of MLPs but maintains some characteristics of KANs.',\n  'However, GR-KAN is not a pure KAN model.',\n  'Instead, it merges advantages from both systems to enhance overall functionality.',\n  'Future Work.',\n  'There are multiple directions of KAT for future research.',\n  'One potential area of exploration is to find alter- native base functions to further improve computational efficiency and compatibility with emerging hardware architectures.',\n  'Currently, rational functions serve as one option, but other possibilities exist.',\n  'These include Fourier transformations [Noe24], Wavelet transforms [BC24b], and Gaussian radial bases [Li24].',\n  'Additionally, expanding the applicability of KAT to other domains beyond vision tasks, such as natural language processing or reinforcement learning, could unlock new opportunities for performance gains.',\n  'Further research could also investigate hybrid models [YZL+22, YSZ+23], or adaptive mechanisms for dynamically selecting between KAN and MLP layers based on the complexity of the task, thereby optimizing resource utilization.',\n  'Finally, addressing the remaining scalability challenges, particularly in terms of memory footprint and inference speed, will be crucial for deploying KAT in real-world applications at scale.',\n  'Acknowledgement We would like to acknowledge that computational work involved in this research work is partially supported by NUS IT‚Äôs Research Computing group using grant numbers NUSREC-HPC-00001.',\n  'We thank Weihao Yu, Qiuhong Shen and Runpeng yu for valuable discussions.',\n  'References [Agh24] Alireza Afzal Aghaei.',\n  'rkan: Rational kolmogorov-arnold networks.',\n  'arXiv preprint arXiv:2406.14495, 2024. [',\n  'BC24a] Zavareh Bozorgasl and Hao Chen.',\n  'Wav-kan: Wavelet kolmogorov-arnold networks.',\n  'arXiv preprint arXiv:2405.12832, 2024. [',\n  'BC24b] Zavareh Bozorgasl and Hao Chen.',\n  'Wav-kan: Wavelet kolmogorov-arnold networks, 2024.',\n  '13'],\n 'page_sents_count_spacy': 41}"},"metadata":{}}]},{"cell_type":"markdown","source":"Nice! –¢–µ–ø–µ—Ä—å —É –Ω–∞—Å –µ—Å—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç–∞—Ç—å —Å —Ç–µ–∫—Å—Ç–æ–º","metadata":{}},{"cell_type":"markdown","source":"–°–¥–µ–ª–∞–µ–º DataFrame, —á—Ç–æ–±—ã –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–∞—à–µ–º dataset'–µ","metadata":{}},{"cell_type":"code","source":"train_text_df = pd.DataFrame(pdf)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:02.083961Z","iopub.execute_input":"2024-10-30T17:02:02.084332Z","iopub.status.idle":"2024-10-30T17:02:02.094429Z","shell.execute_reply.started":"2024-10-30T17:02:02.084284Z","shell.execute_reply":"2024-10-30T17:02:02.093479Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_text_df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:02.095662Z","iopub.execute_input":"2024-10-30T17:02:02.095999Z","iopub.status.idle":"2024-10-30T17:02:02.131545Z","shell.execute_reply.started":"2024-10-30T17:02:02.095967Z","shell.execute_reply":"2024-10-30T17:02:02.130606Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"       page_number  page_char_counts  page_word_counts  page_sents_counts  \\\ncount    19.000000         19.000000         19.000000          19.000000   \nmean     10.000000       3368.000000        525.947368          34.052632   \nstd       5.627314        905.488021        203.089874          16.379098   \nmin       1.000000       1110.000000        182.000000           2.000000   \n25%       5.500000       2952.000000        450.500000          27.500000   \n50%      10.000000       3268.000000        494.000000          32.000000   \n75%      14.500000       3710.000000        555.000000          38.500000   \nmax      19.000000       5446.000000       1260.000000          66.000000   \n\n       page_token_counts(approximately)  page_sents_count_spacy  \ncount                         19.000000               19.000000  \nmean                         842.000000               32.684211  \nstd                          226.372005               16.626794  \nmin                          277.500000                2.000000  \n25%                          738.000000               22.500000  \n50%                          817.000000               32.000000  \n75%                          927.500000               39.000000  \nmax                         1361.500000               61.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>page_number</th>\n      <th>page_char_counts</th>\n      <th>page_word_counts</th>\n      <th>page_sents_counts</th>\n      <th>page_token_counts(approximately)</th>\n      <th>page_sents_count_spacy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>19.000000</td>\n      <td>19.000000</td>\n      <td>19.000000</td>\n      <td>19.000000</td>\n      <td>19.000000</td>\n      <td>19.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>10.000000</td>\n      <td>3368.000000</td>\n      <td>525.947368</td>\n      <td>34.052632</td>\n      <td>842.000000</td>\n      <td>32.684211</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.627314</td>\n      <td>905.488021</td>\n      <td>203.089874</td>\n      <td>16.379098</td>\n      <td>226.372005</td>\n      <td>16.626794</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1110.000000</td>\n      <td>182.000000</td>\n      <td>2.000000</td>\n      <td>277.500000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.500000</td>\n      <td>2952.000000</td>\n      <td>450.500000</td>\n      <td>27.500000</td>\n      <td>738.000000</td>\n      <td>22.500000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>10.000000</td>\n      <td>3268.000000</td>\n      <td>494.000000</td>\n      <td>32.000000</td>\n      <td>817.000000</td>\n      <td>32.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>14.500000</td>\n      <td>3710.000000</td>\n      <td>555.000000</td>\n      <td>38.500000</td>\n      <td>927.500000</td>\n      <td>39.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>19.000000</td>\n      <td>5446.000000</td>\n      <td>1260.000000</td>\n      <td>66.000000</td>\n      <td>1361.500000</td>\n      <td>61.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"–ü–æ—Ä–∞ —Ä–∞–∑–±–∏–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏","metadata":{}},{"cell_type":"markdown","source":"–ù–∏–∂–µ, –ø—Ä–∏–º–µ—Ä, –∫–∞–∫ –º—ã –±—É–¥–µ–º –±–∏—Ç—å –Ω–∞ —á–∞–Ω–∫–∏ 25 –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏—Ö —á–∏—Å–ª–µ —Å 0 –¥–æ 24","metadata":{}},{"cell_type":"code","source":"num_sents_chunk = 5\n\ndef split_list_of_text_into_chunks(input_list: list, slice_size: int):\n    return [input_list[i: i + slice_size] for i in range(0, len(input_list), slice_size)]\n\ntest = list(range(25))\nsplit_list_of_text_into_chunks(test, num_sents_chunk)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:02.132932Z","iopub.execute_input":"2024-10-30T17:02:02.133345Z","iopub.status.idle":"2024-10-30T17:02:02.142631Z","shell.execute_reply.started":"2024-10-30T17:02:02.133298Z","shell.execute_reply":"2024-10-30T17:02:02.141746Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[[0, 1, 2, 3, 4],\n [5, 6, 7, 8, 9],\n [10, 11, 12, 13, 14],\n [15, 16, 17, 18, 19],\n [20, 21, 22, 23, 24]]"},"metadata":{}}]},{"cell_type":"markdown","source":"–ê —Ç–µ–ø–µ—Ä—å —Å–¥–µ–ª–∞–µ–º —Ç–æ –∂–µ —Å–∞–º–æ–µ –¥–ª—è –Ω–∞—à–µ–≥–æ —Ç–µ–∫—Å—Ç–∞","metadata":{}},{"cell_type":"code","source":"for item in tqdm(pdf):\n    item['sents_chunks'] = split_list_of_text_into_chunks(input_list=item['sents'], slice_size=num_sents_chunk)\n    item['num_chunks'] = len(item['sents_chunks'])","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:02.143857Z","iopub.execute_input":"2024-10-30T17:02:02.144194Z","iopub.status.idle":"2024-10-30T17:02:02.172644Z","shell.execute_reply.started":"2024-10-30T17:02:02.144163Z","shell.execute_reply":"2024-10-30T17:02:02.171743Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cadd2e926dc24b719436c6599bb8749e"}},"metadata":{}}]},{"cell_type":"markdown","source":"–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –¥–µ–ª–∞—Ç—å —á–∞–Ω–∫–∏","metadata":{}},{"cell_type":"code","source":"import re\nfrom tqdm import tqdm\n\npdf_chunks = []\n\nfor i, item in tqdm(enumerate(pdf)):\n    if i % 1 == 0:\n        print(f\"Processed {i} items\")\n    \n    for sent_chunks in item['sents_chunks']:\n        chunk_dict = {}\n        chunk_dict['page_number'] = item['page_number']\n        \n        joined_sent_chunk = \" \".join(sent_chunks).replace(\"  \", \" \").strip()\n        joined_sent_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sent_chunk)\n        \n        chunk_dict['sents_chunks'] = joined_sent_chunk\n        chunk_dict['chunk_char_count'] = len(joined_sent_chunk)\n        chunk_dict['chunk_word_count'] = len(joined_sent_chunk.split())\n        chunk_dict['chunk_token_count'] = len(joined_sent_chunk) / 4\n        \n        pdf_chunks.append(chunk_dict)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:02.173846Z","iopub.execute_input":"2024-10-30T17:02:02.174165Z","iopub.status.idle":"2024-10-30T17:02:02.189351Z","shell.execute_reply.started":"2024-10-30T17:02:02.174135Z","shell.execute_reply":"2024-10-30T17:02:02.188460Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"19it [00:00, 5487.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 0 items\nProcessed 1 items\nProcessed 2 items\nProcessed 3 items\nProcessed 4 items\nProcessed 5 items\nProcessed 6 items\nProcessed 7 items\nProcessed 8 items\nProcessed 9 items\nProcessed 10 items\nProcessed 11 items\nProcessed 12 items\nProcessed 13 items\nProcessed 14 items\nProcessed 15 items\nProcessed 16 items\nProcessed 17 items\nProcessed 18 items\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"pdf_chunks[0]","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:02.190719Z","iopub.execute_input":"2024-10-30T17:02:02.191012Z","iopub.status.idle":"2024-10-30T17:02:02.196994Z","shell.execute_reply.started":"2024-10-30T17:02:02.190981Z","shell.execute_reply":"2024-10-30T17:02:02.196057Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'page_number': 1,\n 'sents_chunks': 'Kolmogorov‚ÄìArnold Transformer Xingyi Yang Xinchao Wang National University of Singapore xyang@u.nus.edu; xinchao@nus.edu.sg Input Emb. Norm Attention Norm MLP Transformer Input Emb. Norm Attention Norm KAN ViT + KAN ViT KAT* DeiT ViT + KAN KAT Input Emb. Norm Attention Norm GR-KAN KAT(Ours) Figure 1: (Left) Architecture of standard transformer (e.g. ViT), ViT+KAN which substitutes the MLP with a KAN, and our KAT model. In KAT, the MLP layers in transformers are replaced with GR-KAN layers. (',\n 'chunk_char_count': 496,\n 'chunk_word_count': 76,\n 'chunk_token_count': 124.0}"},"metadata":{}}]},{"cell_type":"markdown","source":"–ù—É –≤–æ—Ç –º—ã –∏ —Å–¥–µ–ª–∞–ª–∏ —á–∞–Ω–∫–∏! –£—Ä–∞ —É—Ä–∞, –º—ã –º–æ–ª–æ–¥—Ü—ã! –ù–æ –≤—Å–µ –ª–∏ —á–∞–Ω–∫–∏ –Ω–∞–º –Ω—É–∂–Ω—ã? –î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –¥–∞–Ω–Ω—ã–µ –æ –Ω–∞—à–µ–º dataset'–µ","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(pdf_chunks)\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:02.198351Z","iopub.execute_input":"2024-10-30T17:02:02.198740Z","iopub.status.idle":"2024-10-30T17:02:02.222166Z","shell.execute_reply.started":"2024-10-30T17:02:02.198697Z","shell.execute_reply":"2024-10-30T17:02:02.221231Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"       page_number  chunk_char_count  chunk_word_count  chunk_token_count\ncount   134.000000        134.000000        134.000000         134.000000\nmean     10.052239        477.216418         75.097015         119.304104\nstd       5.263461        488.618605        109.526450         122.154651\nmin       1.000000          2.000000          1.000000           0.500000\n25%       5.250000        296.500000         41.000000          74.125000\n50%      11.000000        420.000000         65.000000         105.000000\n75%      15.000000        570.000000         81.000000         142.500000\nmax      19.000000       5446.000000       1260.000000        1361.500000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>page_number</th>\n      <th>chunk_char_count</th>\n      <th>chunk_word_count</th>\n      <th>chunk_token_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>134.000000</td>\n      <td>134.000000</td>\n      <td>134.000000</td>\n      <td>134.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>10.052239</td>\n      <td>477.216418</td>\n      <td>75.097015</td>\n      <td>119.304104</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.263461</td>\n      <td>488.618605</td>\n      <td>109.526450</td>\n      <td>122.154651</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.250000</td>\n      <td>296.500000</td>\n      <td>41.000000</td>\n      <td>74.125000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>11.000000</td>\n      <td>420.000000</td>\n      <td>65.000000</td>\n      <td>105.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>15.000000</td>\n      <td>570.000000</td>\n      <td>81.000000</td>\n      <td>142.500000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>19.000000</td>\n      <td>5446.000000</td>\n      <td>1260.000000</td>\n      <td>1361.500000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"–î—É–º–∞—é, —á–∞–Ω–∫–∏, –≤ –∫–æ—Ç–æ—Ä—ã—Ö —É –Ω–∞—Å –º–µ–Ω—å—à–µ 50 —Ç–æ–∫–µ–Ω–æ–≤ –Ω–µ—Ç —Å–º—ã—Å–ª–∞ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å, —Ç–∞–º –º–∞–ª–æ –∫–æ–Ω—Ç–µ–∫—Ç—Å–∞\n\n**–ó–∞–¥–∞—á–∞:** –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –ø—Ä–∞–≤ –ª–∏ —è? –î–ª—è —ç—Ç–æ–≥–æ –Ω–∞–ø–∏—à–∏—Ç–µ –≤ —è—á–µ–π–∫–µ –Ω–∏–∂–µ –∫–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∫–∞–∂–µ—Ç, –≤ –∫–∞–∫–∏—Ö —á–∞–Ω–∫–∞—Ö —É –Ω–∞—Å < 50 —Ç–æ–∫–µ–Ω–æ–≤","metadata":{}},{"cell_type":"markdown","source":"–°–Ω–∏–∑—É –æ—Ç–≤–µ—Ç, –Ω–µ –ø–æ–¥—Å–º–∞—Ç—Ä–∏–≤–∞–π—Ç–µ! –î–ª—è –Ω–∞—á–∞–ª–∞,–ø–æ–¥—É–º–∞–π—Ç–µ —Å–∞–º–∏","metadata":{}},{"cell_type":"code","source":"#your code here","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:02.226312Z","iopub.execute_input":"2024-10-30T17:02:02.226647Z","iopub.status.idle":"2024-10-30T17:02:02.230930Z","shell.execute_reply.started":"2024-10-30T17:02:02.226613Z","shell.execute_reply":"2024-10-30T17:02:02.229961Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"min_token_length = 50","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:02.232172Z","iopub.execute_input":"2024-10-30T17:02:02.232508Z","iopub.status.idle":"2024-10-30T17:02:02.240404Z","shell.execute_reply.started":"2024-10-30T17:02:02.232475Z","shell.execute_reply":"2024-10-30T17:02:02.239445Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"for index, row in df[df['chunk_token_count'] <= min_token_length].iterrows():\n    print(f\"Chunk token count: {row['chunk_token_count']} | Text: {row['sents_chunks']}\")","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-10-30T17:02:02.241515Z","iopub.execute_input":"2024-10-30T17:02:02.241867Z","iopub.status.idle":"2024-10-30T17:02:02.254227Z","shell.execute_reply.started":"2024-10-30T17:02:02.241832Z","shell.execute_reply":"2024-10-30T17:02:02.253322Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Chunk token count: 30.5 | Text: At their core, transformers are built upon two fundamental components: attention 1 arXiv:2409.10594v1 [cs. LG] 16 Sep 2024\nChunk token count: 30.5 | Text: √çùëëùëñùëõ ùëñ=1 ùúôùëñ,ùëëùëúùë¢ùë°(ùë•ùëñ) \u0003 , where Œ¶ = Ô£ÆÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞ ùúô1,1(¬∑) ¬∑ ¬∑ ¬∑ ùúô1,ùëëin(¬∑) ... ... ... ùúôùëëout,1(¬∑) ¬∑ ¬∑ ¬∑ ùúôùëëout,ùëëin(¬∑) Ô£πÔ£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª (4) 3\nChunk token count: 31.5 | Text: In practice, we share the parameter for the rational function ùêπfor each group; however, each edge retains a unique scalar ùë§. 6\nChunk token count: 16.0 | Text: ùúô!,! ùúô!,# ùúô!,$ ùúô!,% ùúô#,! ùúô#,# ùúô#,$ ùúô#,% ùúô$,! ùúô$,# ùúô$,$ ùúô$,% ùúô%,!\nChunk token count: 30.25 | Text: ùúô%,# ùúô%,$ ùúô%,% ùúô ùúô ùúô ùúô ùúô ùúô ùúô ùúô ùúô ùúô ùúô ùúô ùúô ùúô ùúô ùúô Input Channels Output Channels Vanilla KAN Pre-Act MLP ùúô&! ùúô&! ùúô&! ùúô&! ùúô&!\nChunk token count: 20.5 | Text: The comparison of the number of parameters and computation is listed in Table 2. 7\nChunk token count: 23.25 | Text: IN-1k Top-1 Identity Identity 69.7 Swish Swish 74.4 Identity GeLU 74.5 Identity Swish 74.6 12\nChunk token count: 0.5 | Text: 13\nChunk token count: 49.0 | Text: JMLR Workshop and Conference Proceedings, 2010. [ GR74] William J Gordon and Richard F Riesenfeld. B-spline curves and surfaces. In Computer aided geometric design, pages 95‚Äì126. Elsevier, 1974. [\nChunk token count: 49.5 | Text: HG16] Dan Hendrycks and Kevin Gimpel. Gaussian error linear units (gelus). arXiv preprint arXiv:1606.08415, 2016. [ HGDG17] Kaiming He, Georgia Gkioxari, Piotr Doll√°r, and Ross Girshick. Mask r-cnn.\nChunk token count: 0.5 | Text: 14\nChunk token count: 44.5 | Text: Rational function neural network. Neural Computation, 5(6):928‚Äì938, 1993. [ LH19] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization, 2019. [ Li24] Ziyao Li.\nChunk token count: 0.5 | Text: 15\nChunk token count: 42.0 | Text: arXiv preprint arXiv:1710.05941, 2017. [ SH05] Christian Sigg and Markus Hadwiger. Fast third-order texture filtering. GPU gems, 2:313‚Äì329, 2005. [ Sha20] Noam Shazeer.\nChunk token count: 0.5 | Text: 16\nChunk token count: 0.5 | Text: 17\n","output_type":"stream"}]},{"cell_type":"code","source":"pdf_chunks_lower_than_50_tokens = df[df['chunk_token_count'] > min_token_length].to_dict(orient='records')\npdf_chunks_lower_than_50_tokens[:2]","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:02.255509Z","iopub.execute_input":"2024-10-30T17:02:02.255853Z","iopub.status.idle":"2024-10-30T17:02:02.268461Z","shell.execute_reply.started":"2024-10-30T17:02:02.255821Z","shell.execute_reply":"2024-10-30T17:02:02.267557Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[{'page_number': 1,\n  'sents_chunks': 'Kolmogorov‚ÄìArnold Transformer Xingyi Yang Xinchao Wang National University of Singapore xyang@u.nus.edu; xinchao@nus.edu.sg Input Emb. Norm Attention Norm MLP Transformer Input Emb. Norm Attention Norm KAN ViT + KAN ViT KAT* DeiT ViT + KAN KAT Input Emb. Norm Attention Norm GR-KAN KAT(Ours) Figure 1: (Left) Architecture of standard transformer (e.g. ViT), ViT+KAN which substitutes the MLP with a KAN, and our KAT model. In KAT, the MLP layers in transformers are replaced with GR-KAN layers. (',\n  'chunk_char_count': 496,\n  'chunk_word_count': 76,\n  'chunk_token_count': 124.0},\n {'page_number': 1,\n  'sents_chunks': 'Right) Performance on the ImageNet dataset. KAT‚àóindicates that the model was initialized using a pre-trained ViT. Generally, KAT outperforms both the ViT and DeiT models. ViT+KAN performs poorly on ImageNet-level training. Abstract Transformers stand as the cornerstone of mordern deep learning. Traditionally, these models rely on multi-layer perceptron (MLP) layers to mix the information between channels.',\n  'chunk_char_count': 408,\n  'chunk_word_count': 56,\n  'chunk_token_count': 102.0}]"},"metadata":{}}]},{"cell_type":"markdown","source":"–ù—É –∞ —Ç–µ–ø–µ—Ä—å —Å–∞–º–æ–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–µ, –¥–∞–≤–∞–π—Ç–µ –¥–µ–ª–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–∞! –î–ª—è —ç—Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫—É sentence-transformers","metadata":{}},{"cell_type":"code","source":"emb_model = SentenceTransformer(model_name_or_path='all-mpnet-base-v2', device='cpu')","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:02.269742Z","iopub.execute_input":"2024-10-30T17:02:02.270194Z","iopub.status.idle":"2024-10-30T17:02:03.735413Z","shell.execute_reply.started":"2024-10-30T17:02:02.270151Z","shell.execute_reply":"2024-10-30T17:02:03.734561Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"for item in tqdm(pdf_chunks_lower_than_50_tokens):\n    item['emb'] = emb_model.encode(item['sents_chunks'], convert_to_tensor=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:03.736640Z","iopub.execute_input":"2024-10-30T17:02:03.736985Z","iopub.status.idle":"2024-10-30T17:02:25.674741Z","shell.execute_reply.started":"2024-10-30T17:02:03.736950Z","shell.execute_reply":"2024-10-30T17:02:25.673744Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"  0%|          | 0/118 [00:00<?, ?it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d16c5ae5bd64f839cb9e4cbc2abe96e"}},"metadata":{}},{"name":"stderr","text":"  1%|          | 1/118 [00:00<00:27,  4.25it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b1617a7b59f49d29672dc6c2964764f"}},"metadata":{}},{"name":"stderr","text":"  2%|‚ñè         | 2/118 [00:00<00:21,  5.33it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"033d9afa746c47d29231794ddcb4620f"}},"metadata":{}},{"name":"stderr","text":"  3%|‚ñé         | 3/118 [00:00<00:20,  5.52it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb9316ca52604b60af7e4cc360e76387"}},"metadata":{}},{"name":"stderr","text":"  3%|‚ñé         | 4/118 [00:00<00:19,  5.79it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2894c6a331c484a93712706004518a2"}},"metadata":{}},{"name":"stderr","text":"  4%|‚ñç         | 5/118 [00:00<00:18,  6.24it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24380276b1264e35b8aa9d2cd20d4c3f"}},"metadata":{}},{"name":"stderr","text":"  5%|‚ñå         | 6/118 [00:01<00:18,  6.22it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32b2b0755a444f4caedd194fd35f415e"}},"metadata":{}},{"name":"stderr","text":"  6%|‚ñå         | 7/118 [00:01<00:18,  6.03it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5321cdee29a4b45980cb143f5005114"}},"metadata":{}},{"name":"stderr","text":"  7%|‚ñã         | 8/118 [00:01<00:18,  6.00it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fc579cbb9cc4423ac99f562f7d6a685"}},"metadata":{}},{"name":"stderr","text":"  8%|‚ñä         | 9/118 [00:01<00:18,  6.01it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19965f4ef8b94ce7b12a994a05a17978"}},"metadata":{}},{"name":"stderr","text":"  8%|‚ñä         | 10/118 [00:01<00:17,  6.18it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f29ff49175e4f2586fa10a216f4e720"}},"metadata":{}},{"name":"stderr","text":"  9%|‚ñâ         | 11/118 [00:01<00:17,  5.99it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8be0d5125a0745e88cc65bf490ade724"}},"metadata":{}},{"name":"stderr","text":" 10%|‚ñà         | 12/118 [00:02<00:16,  6.27it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a7a9110a4294c8e996cf325f4ad5d71"}},"metadata":{}},{"name":"stderr","text":" 11%|‚ñà         | 13/118 [00:02<00:17,  6.15it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"058ae8cefad942fa82c944f7872acdb0"}},"metadata":{}},{"name":"stderr","text":" 12%|‚ñà‚ñè        | 14/118 [00:02<00:17,  5.83it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fb74d464f3e45ec9b08daece712e550"}},"metadata":{}},{"name":"stderr","text":" 13%|‚ñà‚ñé        | 15/118 [00:02<00:16,  6.34it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97d1307c76e241ffa7b18080acd30f7d"}},"metadata":{}},{"name":"stderr","text":" 14%|‚ñà‚ñé        | 16/118 [00:02<00:14,  6.81it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21f0a2ad51174f518c307b483b57f8c3"}},"metadata":{}},{"name":"stderr","text":" 14%|‚ñà‚ñç        | 17/118 [00:02<00:16,  6.20it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eefc73e629564b5c9d8537254bfd93bd"}},"metadata":{}},{"name":"stderr","text":" 15%|‚ñà‚ñå        | 18/118 [00:03<00:17,  5.85it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49ce431b870c46ce98909f2fe81c6ca1"}},"metadata":{}},{"name":"stderr","text":" 16%|‚ñà‚ñå        | 19/118 [00:03<00:18,  5.34it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2224a8eceea4d8d9684f7f4724a0799"}},"metadata":{}},{"name":"stderr","text":" 17%|‚ñà‚ñã        | 20/118 [00:03<00:22,  4.37it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a957ad1faae8432e9d295e51193f2f18"}},"metadata":{}},{"name":"stderr","text":" 18%|‚ñà‚ñä        | 21/118 [00:03<00:22,  4.34it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f98fd5880ad4d3eb1a222ef45be3749"}},"metadata":{}},{"name":"stderr","text":" 19%|‚ñà‚ñä        | 22/118 [00:03<00:19,  4.84it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf3d65089e18408c9baf1cbca0351a35"}},"metadata":{}},{"name":"stderr","text":" 19%|‚ñà‚ñâ        | 23/118 [00:04<00:18,  5.18it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcc504eef81f4e3592d58bde6e5ccbb3"}},"metadata":{}},{"name":"stderr","text":" 20%|‚ñà‚ñà        | 24/118 [00:04<00:17,  5.32it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8cae7e6032048fa86f124244b5b0d72"}},"metadata":{}},{"name":"stderr","text":" 21%|‚ñà‚ñà        | 25/118 [00:04<00:17,  5.19it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfe8d01c95b843469cde40cfc8bf6992"}},"metadata":{}},{"name":"stderr","text":" 22%|‚ñà‚ñà‚ñè       | 26/118 [00:04<00:17,  5.14it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31ec9e2f73af42d4a5a333fc102b6cf4"}},"metadata":{}},{"name":"stderr","text":" 23%|‚ñà‚ñà‚ñé       | 27/118 [00:04<00:17,  5.10it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48f4f2f21c294c229d6a7481fb34c2ef"}},"metadata":{}},{"name":"stderr","text":" 24%|‚ñà‚ñà‚ñé       | 28/118 [00:05<00:17,  5.15it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6755eedfd6604e6380904c01c18c5b1e"}},"metadata":{}},{"name":"stderr","text":" 25%|‚ñà‚ñà‚ñç       | 29/118 [00:05<00:19,  4.46it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"233b5bc361e4417ca2f8c4fde413db55"}},"metadata":{}},{"name":"stderr","text":" 25%|‚ñà‚ñà‚ñå       | 30/118 [00:05<00:18,  4.73it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eda6048b508845a7b921f83178921071"}},"metadata":{}},{"name":"stderr","text":" 26%|‚ñà‚ñà‚ñã       | 31/118 [00:05<00:20,  4.17it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2d8224d98f34a35b46bd4db5e43fa4a"}},"metadata":{}},{"name":"stderr","text":" 27%|‚ñà‚ñà‚ñã       | 32/118 [00:05<00:17,  4.92it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20149f0032894f1da07bf97ebaff44fa"}},"metadata":{}},{"name":"stderr","text":" 28%|‚ñà‚ñà‚ñä       | 33/118 [00:06<00:17,  4.92it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e71bceb3f6a4fa2ac65a3200d221b0e"}},"metadata":{}},{"name":"stderr","text":" 29%|‚ñà‚ñà‚ñâ       | 34/118 [00:06<00:20,  4.13it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4d64574a7e549c8a11fd689cd3c7972"}},"metadata":{}},{"name":"stderr","text":" 30%|‚ñà‚ñà‚ñâ       | 35/118 [00:06<00:17,  4.65it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4691762f3ca24698b812ccd7d572e9c6"}},"metadata":{}},{"name":"stderr","text":" 31%|‚ñà‚ñà‚ñà       | 36/118 [00:06<00:17,  4.63it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b94905a80f640c4aaa4ae60c6be7cec"}},"metadata":{}},{"name":"stderr","text":" 31%|‚ñà‚ñà‚ñà‚ñè      | 37/118 [00:07<00:15,  5.10it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88a7845c0ae34083bf3bda6fba21a56a"}},"metadata":{}},{"name":"stderr","text":" 32%|‚ñà‚ñà‚ñà‚ñè      | 38/118 [00:07<00:14,  5.55it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"283d94d5c5144f0d869cb9ea8b1e12d3"}},"metadata":{}},{"name":"stderr","text":" 33%|‚ñà‚ñà‚ñà‚ñé      | 39/118 [00:07<00:14,  5.38it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bbb7c3f10914ae6a945cf2c8dccc06d"}},"metadata":{}},{"name":"stderr","text":" 34%|‚ñà‚ñà‚ñà‚ñç      | 40/118 [00:07<00:16,  4.84it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e834ee5bbabb43258fe1d0f0398d2d6a"}},"metadata":{}},{"name":"stderr","text":" 35%|‚ñà‚ñà‚ñà‚ñç      | 41/118 [00:07<00:16,  4.75it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d15158d1f17447309204cc5d649b7fce"}},"metadata":{}},{"name":"stderr","text":" 36%|‚ñà‚ñà‚ñà‚ñå      | 42/118 [00:07<00:14,  5.18it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3289fc205df348ce968934dc11365c82"}},"metadata":{}},{"name":"stderr","text":" 36%|‚ñà‚ñà‚ñà‚ñã      | 43/118 [00:08<00:14,  5.07it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8327602ab06e47b095b0ccc0300d4ccd"}},"metadata":{}},{"name":"stderr","text":" 37%|‚ñà‚ñà‚ñà‚ñã      | 44/118 [00:08<00:21,  3.42it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30f62e5912cb459aa2bba4d70cfc1117"}},"metadata":{}},{"name":"stderr","text":" 38%|‚ñà‚ñà‚ñà‚ñä      | 45/118 [00:08<00:18,  3.94it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5f064029bec4e1d8738b4f51d935cb4"}},"metadata":{}},{"name":"stderr","text":" 39%|‚ñà‚ñà‚ñà‚ñâ      | 46/118 [00:09<00:16,  4.41it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db83b1897d5a44a98896db598f728b34"}},"metadata":{}},{"name":"stderr","text":" 40%|‚ñà‚ñà‚ñà‚ñâ      | 47/118 [00:09<00:16,  4.20it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b166f420c004d85aaf5bf7ca8ffef9d"}},"metadata":{}},{"name":"stderr","text":" 41%|‚ñà‚ñà‚ñà‚ñà      | 48/118 [00:09<00:14,  4.67it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ebe7a880a8d4c739cc2efe100093881"}},"metadata":{}},{"name":"stderr","text":" 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 49/118 [00:09<00:13,  5.00it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df0bad240a63407ea0c6687563e92049"}},"metadata":{}},{"name":"stderr","text":" 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 50/118 [00:09<00:12,  5.38it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e594b23a3e8445389a79c290031cc6a"}},"metadata":{}},{"name":"stderr","text":" 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 51/118 [00:09<00:12,  5.19it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccab996a94cb4b46832de77e2b3e3015"}},"metadata":{}},{"name":"stderr","text":" 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 52/118 [00:10<00:12,  5.44it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6d5111f5fe24769a4e8934ecba12d5c"}},"metadata":{}},{"name":"stderr","text":" 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 53/118 [00:10<00:11,  5.89it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12a04289e00741f6bdd871dc39874c21"}},"metadata":{}},{"name":"stderr","text":" 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 54/118 [00:10<00:15,  4.05it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83ec336cb1a742c19112201295483ec2"}},"metadata":{}},{"name":"stderr","text":" 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 55/118 [00:10<00:14,  4.36it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f253c936e2ff47d69cfc5049c4ded508"}},"metadata":{}},{"name":"stderr","text":" 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 56/118 [00:11<00:12,  4.77it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3d4127d1f3346a5997b9a39d4afbc5e"}},"metadata":{}},{"name":"stderr","text":" 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 57/118 [00:11<00:15,  3.86it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"376f1136abff4dc9b19bb0ef56942b98"}},"metadata":{}},{"name":"stderr","text":" 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 58/118 [00:11<00:14,  4.25it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73dbd77ea42849249e10d077ad2f584d"}},"metadata":{}},{"name":"stderr","text":" 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 59/118 [00:11<00:12,  4.73it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f1d6be4f6d046799e0213dff945450c"}},"metadata":{}},{"name":"stderr","text":" 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 60/118 [00:12<00:12,  4.60it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"788e60ed614f47d9bdbba879af4dce2b"}},"metadata":{}},{"name":"stderr","text":" 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 61/118 [00:12<00:12,  4.70it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e2b5f86eddf4626af4a5a1f7114e443"}},"metadata":{}},{"name":"stderr","text":" 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 62/118 [00:12<00:11,  4.79it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27b0d915622d4c3c9177f3afbddf773d"}},"metadata":{}},{"name":"stderr","text":" 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 63/118 [00:12<00:11,  4.87it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b9728c3d2fd4b0ab7592858a921bfae"}},"metadata":{}},{"name":"stderr","text":" 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 64/118 [00:12<00:09,  5.43it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20e08f76dfad4d199da394d1567eb058"}},"metadata":{}},{"name":"stderr","text":" 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 65/118 [00:12<00:09,  5.75it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"981bd64720ef4e3498954c40b527d5a3"}},"metadata":{}},{"name":"stderr","text":" 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 66/118 [00:13<00:10,  5.20it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6820f860589d47d1b97f32d915710980"}},"metadata":{}},{"name":"stderr","text":" 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 67/118 [00:13<00:09,  5.50it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cef169c224446249442f39e6742c762"}},"metadata":{}},{"name":"stderr","text":" 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 68/118 [00:13<00:09,  5.43it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f8308355e3142dfb938ca6b28a62c37"}},"metadata":{}},{"name":"stderr","text":" 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 69/118 [00:13<00:08,  5.76it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78adaf6c7ccb4d3a815dca4c32d3dc84"}},"metadata":{}},{"name":"stderr","text":" 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 70/118 [00:13<00:09,  5.31it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d71933874aa4938a4ef2c11af2f614b"}},"metadata":{}},{"name":"stderr","text":" 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 71/118 [00:14<00:08,  5.64it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93e2ec1ee3c14f6488016f1f676c0fcc"}},"metadata":{}},{"name":"stderr","text":" 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 72/118 [00:14<00:07,  6.00it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34dcf8e8c6e941438fb6a467def481d5"}},"metadata":{}},{"name":"stderr","text":" 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 73/118 [00:14<00:07,  6.04it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65a511011f2346f994c4cfc6c9c491ae"}},"metadata":{}},{"name":"stderr","text":" 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 74/118 [00:14<00:06,  6.39it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cddd734005f7417bbbf384ae2f4492a0"}},"metadata":{}},{"name":"stderr","text":" 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 75/118 [00:14<00:07,  5.77it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b12a401fe34a41a79fca2ce972f82115"}},"metadata":{}},{"name":"stderr","text":" 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 76/118 [00:14<00:07,  5.86it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19eded93409946bbbd4e3cbc06c61439"}},"metadata":{}},{"name":"stderr","text":" 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 77/118 [00:14<00:06,  6.04it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97a3c73f4cf445e295580d60564259da"}},"metadata":{}},{"name":"stderr","text":" 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 78/118 [00:15<00:06,  6.19it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"299ceee310964c26ba87d1485edb5b24"}},"metadata":{}},{"name":"stderr","text":" 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 79/118 [00:15<00:06,  6.48it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4df06df5f04401dacd3f01a9ad609dc"}},"metadata":{}},{"name":"stderr","text":" 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 80/118 [00:15<00:06,  6.10it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b81d03aea15947f886adf12204544694"}},"metadata":{}},{"name":"stderr","text":" 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 81/118 [00:15<00:05,  6.17it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad43c55f749b49889ac0c8e8c08e9b14"}},"metadata":{}},{"name":"stderr","text":" 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 82/118 [00:15<00:05,  6.04it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bbeaba023ae4146a9c2f111774efb72"}},"metadata":{}},{"name":"stderr","text":" 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 83/118 [00:15<00:05,  5.95it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9ee41c1b86d402dadd2111267883fe8"}},"metadata":{}},{"name":"stderr","text":" 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 84/118 [00:16<00:06,  5.42it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"758883f487264371a9eacb4946a2dc2a"}},"metadata":{}},{"name":"stderr","text":" 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 85/118 [00:16<00:05,  5.92it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"575d70ae9a51465486d3a93886cfbd52"}},"metadata":{}},{"name":"stderr","text":" 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 86/118 [00:16<00:05,  6.21it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0734831e799a44aab045750b8cbc3fc0"}},"metadata":{}},{"name":"stderr","text":" 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 87/118 [00:16<00:04,  6.43it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6efa253fb7bd47009fed5d3bc246c8e6"}},"metadata":{}},{"name":"stderr","text":" 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 88/118 [00:16<00:04,  6.58it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8df85fc558448fb83f170a701aee7d8"}},"metadata":{}},{"name":"stderr","text":" 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 89/118 [00:16<00:04,  6.63it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"162b2f141ff04698ae22ed184f459094"}},"metadata":{}},{"name":"stderr","text":" 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 90/118 [00:17<00:04,  6.57it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"834836208f3846fab901305a94633d16"}},"metadata":{}},{"name":"stderr","text":" 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 91/118 [00:17<00:04,  6.55it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"064628fd88af49fc83c3a43aa92cc8e8"}},"metadata":{}},{"name":"stderr","text":" 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 92/118 [00:17<00:03,  6.86it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34a340a5e6f749339c78c140b943010a"}},"metadata":{}},{"name":"stderr","text":" 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 93/118 [00:17<00:03,  6.64it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66fdb7342df546ab977403dde0c41f8d"}},"metadata":{}},{"name":"stderr","text":" 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 94/118 [00:17<00:03,  6.29it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"653ae3bcdfdc457c82bbdf1a7c14d076"}},"metadata":{}},{"name":"stderr","text":" 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 95/118 [00:17<00:03,  6.52it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fcc6c0635824c50b8c48616432ed730"}},"metadata":{}},{"name":"stderr","text":" 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 96/118 [00:18<00:03,  6.02it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b3e496a103946c8948eb041685b8fb0"}},"metadata":{}},{"name":"stderr","text":" 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 97/118 [00:18<00:03,  6.35it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47ad543b4da34b3189935fe20312be11"}},"metadata":{}},{"name":"stderr","text":" 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 98/118 [00:18<00:03,  6.62it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9e62f23aa97403fb3b003859fa615ab"}},"metadata":{}},{"name":"stderr","text":" 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 99/118 [00:18<00:02,  6.60it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9e411bc78be4ccea450c227e8512f19"}},"metadata":{}},{"name":"stderr","text":" 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 100/118 [00:18<00:02,  6.83it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b389be03a1f4243961e7d31a0c31278"}},"metadata":{}},{"name":"stderr","text":" 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 101/118 [00:18<00:02,  6.82it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"004102287fd141f68f63e51abde7a09c"}},"metadata":{}},{"name":"stderr","text":" 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 102/118 [00:18<00:02,  6.75it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7af84d148d0453897d6b34bf38e4552"}},"metadata":{}},{"name":"stderr","text":" 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 103/118 [00:19<00:02,  6.86it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87d6e36adf34495aba60e9a1921f67a6"}},"metadata":{}},{"name":"stderr","text":" 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 104/118 [00:19<00:02,  6.78it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eacca2fd88b64e14b1d0e078564ee1ad"}},"metadata":{}},{"name":"stderr","text":" 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 105/118 [00:19<00:01,  7.01it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d04b99517854679bdf94ce9f4051433"}},"metadata":{}},{"name":"stderr","text":" 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 106/118 [00:19<00:01,  6.87it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b4049f05d294fa8a1069e12b2c60172"}},"metadata":{}},{"name":"stderr","text":" 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 107/118 [00:19<00:01,  6.45it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d864152429149a7aae87938ae00c498"}},"metadata":{}},{"name":"stderr","text":" 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 108/118 [00:19<00:01,  6.72it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"556f52fc7074439bbd66ba096183fcd5"}},"metadata":{}},{"name":"stderr","text":" 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 109/118 [00:19<00:01,  6.42it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3101f7715d95485eb3b0b4103171dab0"}},"metadata":{}},{"name":"stderr","text":" 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 110/118 [00:20<00:01,  6.13it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53533b4966ab4a3a938a8c5d583eb8a1"}},"metadata":{}},{"name":"stderr","text":" 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 111/118 [00:20<00:01,  6.22it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ac26f2c071c48d6b6f317b86f31ea35"}},"metadata":{}},{"name":"stderr","text":" 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 112/118 [00:20<00:00,  6.33it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfef819ba8ce43898eec90b15abe7d9a"}},"metadata":{}},{"name":"stderr","text":" 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 113/118 [00:20<00:00,  6.29it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16ea142574b34777b2a8238da0d018a1"}},"metadata":{}},{"name":"stderr","text":" 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 114/118 [00:20<00:00,  5.21it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef65c70b51fe41bca770df0ad3f0ac2e"}},"metadata":{}},{"name":"stderr","text":" 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 115/118 [00:20<00:00,  5.52it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"385e37ff945a469faa72b3951f1b8aa8"}},"metadata":{}},{"name":"stderr","text":" 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 116/118 [00:21<00:00,  5.60it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fe92d7e88e04746999941ca5863cf0a"}},"metadata":{}},{"name":"stderr","text":" 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 117/118 [00:21<00:00,  5.11it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec6aa7be4dd24f159721d541fcab2569"}},"metadata":{}},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 118/118 [00:21<00:00,  5.38it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"pdf_chunks_lower_than_50_tokens[0]","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:25.676151Z","iopub.execute_input":"2024-10-30T17:02:25.676570Z","iopub.status.idle":"2024-10-30T17:02:25.695321Z","shell.execute_reply.started":"2024-10-30T17:02:25.676523Z","shell.execute_reply":"2024-10-30T17:02:25.694413Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'page_number': 1,\n 'sents_chunks': 'Kolmogorov‚ÄìArnold Transformer Xingyi Yang Xinchao Wang National University of Singapore xyang@u.nus.edu; xinchao@nus.edu.sg Input Emb. Norm Attention Norm MLP Transformer Input Emb. Norm Attention Norm KAN ViT + KAN ViT KAT* DeiT ViT + KAN KAT Input Emb. Norm Attention Norm GR-KAN KAT(Ours) Figure 1: (Left) Architecture of standard transformer (e.g. ViT), ViT+KAN which substitutes the MLP with a KAN, and our KAT model. In KAT, the MLP layers in transformers are replaced with GR-KAN layers. (',\n 'chunk_char_count': 496,\n 'chunk_word_count': 76,\n 'chunk_token_count': 124.0,\n 'emb': array([ 6.57844450e-03, -6.12231344e-02, -5.16507681e-03, -1.08807264e-02,\n        -1.97361633e-02, -1.90196175e-03, -1.62605953e-03,  8.01866874e-03,\n        -3.61742303e-02, -8.98579787e-03, -1.86397918e-02,  1.54045913e-02,\n         9.22136847e-03,  2.02582087e-02,  4.54471484e-02, -3.32390890e-02,\n        -1.93106495e-02,  1.74438264e-02, -7.57664517e-02, -5.12021668e-02,\n         3.45781334e-02, -4.56750616e-02, -1.99191570e-02,  6.10356815e-02,\n         1.06963320e-02,  1.43031799e-03,  2.21472932e-03, -4.34605367e-02,\n         1.32318567e-02,  2.32388545e-02,  1.31111443e-02, -1.26461890e-02,\n        -2.25799326e-02,  1.01123834e-02,  2.12046052e-06,  1.54076284e-02,\n         2.35242378e-02, -5.61791891e-03,  3.29009853e-02, -9.89790447e-03,\n        -5.37268408e-02, -5.65674417e-02, -3.87939177e-02, -3.43539603e-02,\n        -1.06200890e-03, -2.66643502e-02,  4.48921882e-02,  7.25218356e-02,\n        -1.47580337e-02,  4.62332293e-02,  4.20648279e-03, -9.32310447e-02,\n        -4.14607348e-03, -2.55513191e-02, -1.25664342e-02, -5.33805750e-02,\n         1.74547210e-02, -3.62652540e-03, -4.32191566e-02, -5.97723834e-02,\n        -2.84864791e-02,  8.11621621e-02,  1.38880294e-02, -5.31343669e-02,\n         4.71157953e-02,  2.72499975e-02, -9.88416839e-03, -1.33042037e-02,\n        -6.78006094e-03,  2.34436039e-02, -2.51915422e-03, -3.39892730e-02,\n        -1.21302959e-02,  3.60677429e-02, -1.75921973e-02,  1.06095277e-01,\n        -3.51478234e-02,  3.29442173e-02,  1.49949891e-02,  1.62506513e-02,\n        -2.39801183e-02,  4.07551602e-02,  1.91935413e-02, -4.83401306e-02,\n        -3.51091065e-02,  6.77436404e-03,  3.64721641e-02, -5.66108488e-02,\n         4.89847083e-03,  2.98209656e-02, -4.58474495e-02,  3.53489374e-03,\n         3.57168950e-02,  3.36023234e-02,  5.48020191e-02, -1.70433894e-03,\n        -7.96064851e-04, -6.89014839e-03, -6.02423288e-02, -4.82231602e-02,\n         9.34552401e-02, -2.07282938e-02,  2.91974600e-02,  8.45012628e-03,\n        -3.77981551e-02,  9.15782675e-02, -4.66143861e-02,  2.86404081e-02,\n        -1.44252349e-02, -9.21265408e-03, -1.68768559e-02, -3.88038415e-03,\n        -1.06273396e-02,  6.75436994e-03, -5.24245715e-03,  1.50427464e-02,\n        -2.53863148e-02,  4.96281907e-02,  3.33137177e-02, -5.43359742e-02,\n         1.32896407e-02, -2.18699351e-02, -5.29970117e-02, -4.29370850e-02,\n        -2.70171333e-02,  3.87553498e-02,  3.61463800e-02, -7.18373209e-02,\n         3.21522094e-02,  4.24060188e-02, -3.97197232e-02,  2.33072825e-02,\n        -1.22071570e-02, -1.38528785e-03, -4.73902654e-03,  1.80044472e-02,\n        -1.17811337e-02,  1.36932209e-02, -2.59649358e-03,  9.80583504e-02,\n        -3.41070183e-02,  1.50537267e-02,  1.47447353e-02, -1.08389964e-03,\n        -1.40725663e-02, -1.32864919e-02,  4.34257975e-03,  3.20361070e-02,\n         2.24457365e-02, -7.57011725e-03,  1.12979803e-02,  2.21347734e-02,\n         1.02137811e-01, -9.76435654e-03,  4.64574769e-02,  1.76001573e-03,\n        -4.79943678e-02,  1.79012287e-02, -4.42514084e-02, -1.73889566e-02,\n        -1.22277662e-02, -2.21081469e-02,  6.47588074e-02,  1.18377106e-02,\n         5.22557925e-03, -8.64937715e-03, -3.27694900e-02, -4.81139943e-02,\n        -6.64780661e-02,  4.36486024e-03,  7.58034317e-03,  4.11514975e-02,\n        -4.52084914e-02, -2.26510372e-02,  1.80940367e-02,  4.23630737e-02,\n         1.06762230e-01,  4.20837216e-02, -3.59440409e-02,  2.10918318e-02,\n         1.47430357e-02,  1.79513134e-02, -3.56785655e-02,  6.55497387e-02,\n        -6.91282377e-02, -1.40538411e-02, -9.01377648e-02,  2.72041820e-02,\n        -4.79867421e-02, -4.61227959e-03, -2.34951600e-02, -2.87931995e-04,\n        -1.78533758e-03, -7.75930136e-02,  5.66783361e-03,  7.80926421e-02,\n        -2.03513410e-02,  8.98784623e-02, -1.97152626e-02, -4.43523601e-02,\n        -3.69544514e-02, -7.46470168e-02, -3.73850502e-02, -1.07008770e-01,\n         3.31282690e-02,  4.03208882e-02, -3.68132293e-02, -9.51717980e-03,\n        -1.02440767e-01,  1.86679568e-02, -9.01762582e-03,  1.12820016e-02,\n        -2.55367104e-02, -2.65122410e-02, -1.94793660e-02,  3.88492718e-02,\n         9.47232265e-03, -1.44162029e-02,  1.78389866e-02, -3.18545215e-02,\n         2.46997066e-02, -3.17348987e-02,  4.76811901e-02, -2.32285522e-02,\n        -1.90617237e-03,  1.48072364e-02,  2.75516026e-02,  4.66840677e-02,\n         2.92265043e-02,  3.20833847e-02,  2.00431850e-02, -7.17291096e-03,\n         3.15025225e-02, -5.04934974e-02, -1.46553097e-02,  6.88377842e-02,\n        -2.52423640e-02,  1.36013823e-02, -4.94054426e-03, -1.16098244e-02,\n         3.08180116e-02,  5.04749492e-02,  8.95996615e-02, -5.24414144e-02,\n        -1.86613090e-02, -2.54156739e-02,  1.84198674e-02, -3.84900868e-02,\n        -3.85194035e-05,  3.64397652e-02,  1.22936652e-03, -1.82439741e-02,\n         9.64159705e-03,  1.60625298e-03,  5.83938498e-04, -2.28347350e-02,\n        -7.01851037e-04, -1.23920878e-02,  4.13972102e-02, -4.76558208e-02,\n         2.23980118e-02, -2.64610425e-02,  3.74321034e-03,  2.47710086e-02,\n        -1.36919525e-02,  3.93732376e-02, -4.59742323e-02, -2.81862281e-02,\n        -1.20308558e-02,  1.14175137e-02,  2.84962486e-02,  3.48345861e-02,\n         1.85392927e-02, -1.05862422e-02,  7.56885931e-02, -3.90763395e-02,\n         4.07184064e-02,  4.05430468e-03, -4.57912236e-02,  7.67496694e-03,\n        -5.76007217e-02, -1.82693238e-05,  4.43682633e-03, -6.15368690e-03,\n         3.29455286e-02,  7.26944581e-02, -4.16411599e-03, -2.86646858e-02,\n        -6.98323697e-02, -1.23484069e-02,  8.75924304e-02,  3.91938016e-02,\n        -3.52060944e-02, -5.87391332e-02, -2.80529354e-02, -5.80041483e-02,\n         3.66477892e-02,  6.36194572e-02,  2.23114695e-02,  5.50715886e-02,\n        -1.50137292e-02,  3.26438211e-02, -7.98554439e-03,  2.15662066e-02,\n        -5.00711054e-02, -3.14266160e-02, -4.74700704e-02,  4.64768559e-02,\n        -1.81004009e-03,  1.00961678e-01, -2.89683342e-02, -1.50027145e-02,\n        -2.19406821e-02, -3.81257497e-02, -2.90902192e-03, -2.62580886e-02,\n         5.71865775e-02,  2.80723851e-02, -4.43172976e-02,  8.34746752e-05,\n         2.80219056e-02,  6.37014285e-02,  3.47915925e-02, -2.17784718e-02,\n        -4.04733932e-03, -3.85143682e-02,  3.22601944e-02,  2.07709987e-02,\n        -4.05941717e-02, -1.02615263e-02,  4.76744249e-02,  4.96852119e-03,\n         4.54107067e-03,  1.44919928e-03,  5.59427179e-02, -2.62195263e-02,\n         8.94523971e-03,  5.77510409e-02,  2.44939215e-02, -2.40205955e-02,\n        -8.31927080e-03, -1.07648624e-02, -2.99264491e-02,  1.62216127e-02,\n         1.13695547e-04, -2.43185516e-02,  3.30284657e-03, -4.30565327e-03,\n        -7.26939887e-02,  1.45842675e-02,  3.44106071e-02,  4.61424552e-02,\n        -1.08750742e-02, -3.16101015e-02, -3.57226916e-02,  9.80506763e-02,\n        -4.24409695e-02,  2.03648228e-02,  4.94216979e-02,  2.06674580e-02,\n         5.32110631e-02,  3.64747504e-03, -4.32374068e-02,  7.59920254e-02,\n        -2.65236273e-02, -2.56159026e-02,  4.58099842e-02, -2.10321322e-02,\n        -1.49810910e-02, -1.11862347e-02,  6.38494939e-02,  1.02334274e-02,\n         2.52007637e-02,  1.19511522e-02, -7.38013536e-02, -7.93539658e-02,\n        -1.16230845e-02,  9.13417526e-03,  2.95686964e-02,  1.87153239e-02,\n         5.01312539e-02, -3.21878344e-02,  9.94342286e-03, -1.12456512e-02,\n         1.74594577e-02, -2.29523759e-02, -1.69368498e-02,  4.44070287e-02,\n        -1.19379601e-02, -1.42552042e-02, -8.12331401e-03,  2.10322719e-02,\n        -4.24119122e-02, -1.17151504e-02, -3.10658328e-02, -3.30515206e-03,\n        -1.80042826e-03,  2.65490673e-02, -5.06506339e-02,  7.53119821e-03,\n        -4.99757519e-03,  7.61788860e-02, -5.16029820e-02,  1.06543852e-02,\n        -2.49488428e-02,  3.46096121e-02,  3.51163484e-02, -1.94576718e-02,\n        -2.83561572e-02, -4.04490754e-02,  3.70858908e-02,  2.98857931e-02,\n         3.75035219e-02, -1.30268680e-02, -8.46854746e-02,  2.75608934e-02,\n        -4.58650105e-02, -3.96875516e-02,  3.49436328e-02, -1.89505778e-02,\n         6.01146705e-02, -3.81557532e-02,  1.85734946e-02, -8.23857915e-03,\n        -1.12660192e-02,  1.80266388e-02,  2.60768887e-02, -6.13831170e-02,\n        -3.12069710e-03,  1.78694222e-02,  9.88739193e-05, -9.81138367e-03,\n        -1.74110830e-02,  5.39008155e-02,  2.91728675e-02, -7.61452541e-02,\n         3.97074260e-02, -5.42156724e-03, -7.82695264e-02, -4.66552898e-02,\n         4.09553945e-02, -2.62961853e-02,  2.02478580e-02,  5.47018200e-02,\n        -1.17748931e-01,  3.93022634e-02, -2.61393674e-02,  4.21683211e-03,\n        -2.29194667e-02, -1.24725765e-02, -4.19994183e-02, -4.60556261e-02,\n         9.34920609e-02,  1.63457338e-02, -5.27667589e-02, -8.32209736e-03,\n        -2.64253560e-02, -2.95267440e-02, -5.19374087e-02,  2.67787799e-02,\n         4.20058891e-02,  1.89753138e-02,  1.69709567e-02,  9.31023806e-03,\n        -4.72381152e-03,  2.32934486e-02, -2.92992648e-02,  8.62818677e-03,\n         4.65243496e-02,  1.81840658e-02, -6.48707375e-02,  7.25625374e-04,\n         1.28445877e-02,  4.24681138e-03,  2.79744007e-02,  3.93110211e-04,\n        -2.68804352e-03, -2.22728569e-02,  9.50711500e-03,  2.46077608e-02,\n        -8.36467894e-04,  8.05640742e-02,  3.11478623e-03,  3.60422581e-02,\n         1.39256415e-03,  5.45061454e-02,  1.81638077e-02,  4.08771001e-02,\n        -1.38857234e-02, -7.65697332e-03,  6.47357926e-02, -7.00323051e-03,\n         3.87539193e-02,  6.94088917e-03,  4.55588959e-02, -1.15647810e-02,\n        -2.09365077e-02,  1.06724519e-02,  5.87989502e-02,  1.30351456e-02,\n        -3.54615552e-03, -1.60964988e-02,  6.40886137e-03,  5.05314097e-02,\n         2.21203361e-02,  4.86192177e-04, -1.32085802e-02,  5.15183583e-02,\n        -2.44149771e-02, -6.55850172e-02,  1.18594002e-02, -6.79949904e-03,\n        -3.42844650e-02, -2.00948380e-02,  7.34570110e-03, -4.46081460e-02,\n         2.94870492e-02,  2.10068319e-02,  4.81313318e-02, -3.60785052e-02,\n         5.63913374e-04,  1.78162307e-02,  1.65740252e-02,  1.46169690e-02,\n         5.38099669e-02, -9.50492080e-03, -1.87450703e-02,  5.70535958e-02,\n        -3.08622438e-02,  8.73053819e-03,  1.80521477e-02, -1.94602869e-02,\n        -5.55621237e-02,  3.44269834e-02,  9.79362335e-03,  1.07228914e-02,\n        -9.68227629e-03,  3.65077667e-02,  1.73475742e-02, -2.05781404e-02,\n        -8.73139314e-03,  2.03848593e-02,  7.38977119e-02, -1.15423603e-02,\n        -6.72074500e-03, -4.77973036e-02,  2.79550571e-02,  3.16653624e-02,\n         3.44957877e-03, -1.01532238e-02, -4.61227493e-03, -3.29154879e-02,\n         6.74288571e-02,  2.70693824e-02,  6.16296344e-02, -5.59790467e-33,\n        -3.86271104e-02,  3.61483246e-02,  1.76589433e-02,  7.15575591e-02,\n        -5.01399115e-03,  3.69066885e-03,  1.44175021e-02, -2.01569330e-02,\n        -5.00252610e-03, -3.76356430e-02, -3.98961343e-02, -1.98835339e-02,\n        -1.25590223e-03,  2.26736180e-02, -2.18148828e-02, -1.38449867e-03,\n        -2.25541834e-02, -6.91242702e-03,  3.23093422e-02,  4.44637751e-03,\n        -7.99865462e-03,  2.14393511e-02,  6.97302222e-02, -6.27181819e-03,\n        -2.17525251e-02,  3.52077745e-02, -4.97083180e-03, -1.93233658e-02,\n        -6.31826371e-02,  1.04196435e-02, -7.77513906e-02,  1.02270823e-02,\n        -1.69832129e-02, -4.71428558e-02,  1.52441571e-02, -3.74061801e-02,\n        -1.78376213e-02,  5.21839261e-02, -1.52873127e-02,  1.75507665e-02,\n         2.00304035e-02, -2.96137761e-02,  4.75660861e-02,  8.67255847e-04,\n        -4.60875928e-02, -2.22039670e-02,  1.32447686e-02, -3.78618087e-03,\n        -7.42753223e-03, -1.99485347e-02, -4.04124707e-03, -1.89843925e-03,\n        -2.92528924e-02, -1.52609386e-02,  4.53981645e-02,  1.31718945e-02,\n        -4.89138700e-02, -5.65809477e-03, -5.27450517e-02,  1.33468639e-02,\n         5.28432392e-02,  3.47222462e-02,  5.06653413e-02,  2.35632639e-02,\n         1.89301856e-02, -3.51976193e-02,  3.65778767e-02,  7.44885532e-03,\n        -6.58507571e-02, -3.47834341e-02,  8.67290702e-03,  2.13778056e-02,\n         5.46857491e-02, -5.46250567e-02, -2.93025468e-02, -4.33557965e-02,\n         1.72874611e-02,  1.30594000e-02, -1.49936313e-02,  5.55985942e-02,\n         9.92621388e-03,  1.15471575e-02, -2.88043879e-02, -8.98903795e-03,\n        -8.67815129e-03, -7.48598352e-02,  1.12938881e-03,  1.88592523e-02,\n        -2.66206521e-03, -1.68863907e-02,  1.23606259e-02,  1.16207832e-02,\n        -4.94177192e-02, -2.74165552e-02,  6.60632327e-02, -5.72028868e-02,\n         4.47460115e-02,  3.28426920e-02, -4.37891409e-02, -1.82109028e-02,\n         1.04429014e-02,  1.91525538e-02,  2.83386355e-04,  1.69757288e-02,\n        -1.66685451e-02,  2.02969965e-02, -1.92303900e-02,  5.41917942e-02,\n        -3.05269416e-02, -1.52533865e-02, -2.97055859e-02, -1.06155025e-02,\n         4.92325574e-02, -2.42456421e-03,  2.96349060e-02, -3.86218950e-02,\n         1.96301788e-02,  5.21880202e-02, -9.48145892e-03,  8.09571054e-03,\n         2.91486830e-02,  3.47109921e-02,  5.49941100e-02,  2.89538279e-02,\n        -1.59321371e-02, -3.96601949e-03, -2.94083133e-02,  3.33498530e-02,\n        -3.01116072e-02, -4.59138677e-02, -9.44625027e-03, -2.69677257e-03,\n         2.74689597e-07,  1.66308973e-02,  2.18530577e-02,  1.22863920e-02,\n        -2.35190000e-02,  6.21808600e-03,  7.62276817e-03,  1.28081739e-02,\n         2.62068696e-02,  3.01246159e-02, -3.58960107e-02, -4.22068387e-02,\n        -3.69902104e-02, -3.78857963e-02, -4.07922305e-02, -3.73267196e-02,\n        -7.17264563e-02, -1.30873546e-02,  4.00228538e-02,  3.34053934e-02,\n        -3.06495670e-02,  2.68545710e-02,  2.79172808e-02,  1.24742724e-02,\n        -6.17239904e-03, -1.10148918e-02,  4.66025755e-04,  5.53550161e-02,\n         2.68534701e-02,  6.05749479e-03,  1.85960922e-02,  6.55341595e-02,\n        -3.98934372e-02, -5.79329068e-03, -7.85388766e-05, -4.21789987e-03,\n         3.51435319e-02,  2.86237877e-02,  3.97070646e-02,  1.01323137e-02,\n        -3.54699977e-02,  4.49390523e-02,  6.92269430e-02, -5.05721644e-02,\n        -4.17574011e-02,  4.54259329e-02, -4.30095159e-02,  1.54964421e-02,\n         1.63590480e-02, -7.13892579e-02, -4.29262929e-02, -3.76123469e-03,\n        -4.83232886e-02,  2.48772930e-02, -2.46716551e-02, -1.68638453e-02,\n        -2.76107248e-02,  1.75238699e-02, -7.63222855e-03,  1.68999154e-02,\n        -9.39163193e-03, -1.56115470e-02,  3.96604761e-02, -4.70239073e-02,\n        -8.00530314e-02,  2.47136727e-02,  1.74764171e-02, -8.50319490e-02,\n         3.08175566e-34, -3.17615308e-02,  2.28976756e-02,  2.28311662e-02,\n         4.68319356e-02, -3.56089212e-02, -3.77735756e-02, -8.99226032e-03,\n         2.06506648e-03, -4.29007597e-02, -1.08889602e-01, -1.25745460e-02],\n       dtype=float32)}"},"metadata":{}}]},{"cell_type":"markdown","source":"–ó–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ! –¢–µ–ø–µ—Ä—å —É –Ω–∞—Å –µ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä—ã —á–∞–Ω–∫–æ–≤!","metadata":{}},{"cell_type":"markdown","source":"–î–∞–≤–∞–π—Ç–µ —Å–æ—Ö—Ä–∞–Ω–∏–º –ø–æ–ª—É—á–∏–≤—à–∏–π—Å—è dataset –≤ csv","metadata":{}},{"cell_type":"code","source":"text_and_embs = pd.DataFrame(pdf_chunks_lower_than_50_tokens)\n\ntext_and_embs.to_csv('/kaggle/working/text_and_embs.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:25.696331Z","iopub.execute_input":"2024-10-30T17:02:25.696621Z","iopub.status.idle":"2024-10-30T17:02:26.540575Z","shell.execute_reply.started":"2024-10-30T17:02:25.696589Z","shell.execute_reply":"2024-10-30T17:02:26.539752Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"text_and_embs = pd.read_csv('/kaggle/working/text_and_embs.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:26.541823Z","iopub.execute_input":"2024-10-30T17:02:26.542220Z","iopub.status.idle":"2024-10-30T17:02:26.567401Z","shell.execute_reply.started":"2024-10-30T17:02:26.542174Z","shell.execute_reply":"2024-10-30T17:02:26.566554Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"–ò–∑-–∑–∞ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∏ csv(–≤—Å–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∫–∞–∫ str) –æ–±—Ä–∞–±–æ—Ç–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∞","metadata":{}},{"cell_type":"code","source":"text_and_embs['emb'] = text_and_embs['emb'].apply(lambda x: np.fromstring(x.strip('[]'), sep=' '))","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:26.568529Z","iopub.execute_input":"2024-10-30T17:02:26.568864Z","iopub.status.idle":"2024-10-30T17:02:26.604841Z","shell.execute_reply.started":"2024-10-30T17:02:26.568830Z","shell.execute_reply":"2024-10-30T17:02:26.603995Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"text_and_embs['emb'] ","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:26.606016Z","iopub.execute_input":"2024-10-30T17:02:26.606401Z","iopub.status.idle":"2024-10-30T17:02:26.621403Z","shell.execute_reply.started":"2024-10-30T17:02:26.606364Z","shell.execute_reply":"2024-10-30T17:02:26.620534Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"0      [0.0065784445, -0.0612231344, -0.00516507681, ...\n1      [-0.00493205618, 0.0052231974, -0.00623739418,...\n2      [-0.03309853, 0.0719859153, -0.0240339786, 0.0...\n3      [-0.0358217433, 0.0798559263, 2.09089831e-05, ...\n4      [-0.0182348043, 0.0463021733, -0.0221040808, 0...\n                             ...                        \n113    [-0.0460388325, -0.0330894254, -0.0186878126, ...\n114    [0.00267366227, -0.0645506606, -0.0324550197, ...\n115    [-0.0228865519, -0.0326952115, 0.00180980505, ...\n116    [0.0235033557, -0.10433425, 0.0111487489, 0.02...\n117    [-0.0124384947, -0.0457091257, -0.0514921285, ...\nName: emb, Length: 118, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"embeds = torch.tensor(np.array((text_and_embs['emb'].tolist())), dtype=torch.float32).to(device)\nembeds[1]","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:26.622809Z","iopub.execute_input":"2024-10-30T17:02:26.623246Z","iopub.status.idle":"2024-10-30T17:02:26.912069Z","shell.execute_reply.started":"2024-10-30T17:02:26.623203Z","shell.execute_reply":"2024-10-30T17:02:26.911147Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"tensor([-4.9321e-03,  5.2232e-03, -6.2374e-03, -6.8223e-03, -4.2219e-03,\n        -3.9679e-03,  1.0500e-02, -5.0458e-03, -6.3188e-02,  6.7887e-03,\n        -3.9027e-02,  1.1444e-02, -5.8736e-03,  2.3388e-02,  2.4911e-02,\n        -4.1258e-02,  2.2229e-02,  4.8294e-02, -1.0745e-01, -4.3620e-02,\n        -2.0787e-02, -6.2074e-02, -2.1381e-02,  3.3273e-02, -1.6720e-02,\n         6.3777e-03, -9.4501e-03,  2.1166e-02,  4.1475e-03, -1.4575e-02,\n         4.0760e-02, -5.7001e-03, -2.3356e-02,  3.6981e-02,  2.2433e-06,\n         9.3525e-03,  3.4099e-02, -2.0714e-03, -2.4955e-03,  5.7343e-02,\n        -3.1573e-02, -1.3271e-02, -1.0897e-02, -5.8755e-03, -1.5861e-02,\n        -5.6963e-02,  7.8531e-02,  5.3214e-02,  1.0906e-02,  6.0941e-02,\n        -2.0867e-03, -2.6766e-02,  2.3060e-02, -2.8427e-02, -4.9710e-02,\n        -6.2726e-03, -1.2307e-02, -1.6431e-03, -7.3872e-02, -3.2149e-02,\n        -1.7307e-02,  3.6560e-02,  5.7437e-02,  2.2651e-02,  2.1581e-02,\n         6.4225e-02, -3.1525e-02, -2.1000e-02,  7.2817e-03,  3.9450e-02,\n        -2.9240e-02,  1.0060e-02, -1.1541e-02,  1.7148e-02, -3.6617e-02,\n         6.3886e-02, -3.1512e-02, -1.4681e-02,  2.2858e-03, -8.3514e-03,\n        -6.2623e-02,  6.2157e-02,  3.0435e-02, -2.5936e-02, -5.0452e-02,\n        -1.8157e-02,  4.2654e-02, -1.1002e-02, -2.3263e-03,  2.3024e-02,\n        -5.0615e-02, -2.7066e-02, -1.9727e-02, -2.3186e-02,  1.6009e-02,\n        -8.2971e-03, -2.4020e-02, -2.8421e-02, -3.9599e-02, -6.1749e-02,\n         2.6604e-02,  1.5772e-02, -4.9211e-02, -3.2978e-02, -5.0842e-02,\n         4.1957e-02, -5.9022e-02,  8.9114e-02, -1.6855e-02, -2.6371e-04,\n        -6.7192e-02, -2.2107e-02, -1.6917e-02,  3.0461e-02,  3.6032e-02,\n        -5.9580e-03, -5.0896e-02,  2.9830e-02,  2.7319e-02, -5.8099e-02,\n         2.4474e-02,  7.6683e-03, -2.7199e-02,  3.4087e-03, -3.6062e-02,\n         5.7142e-02,  1.3730e-02,  1.3226e-02,  1.1926e-02, -4.2101e-02,\n        -1.2860e-02, -5.1188e-03, -7.1232e-03, -3.5947e-02,  2.4193e-02,\n         7.4696e-02, -1.9235e-02, -3.0311e-02, -2.6944e-02,  5.2637e-02,\n         7.1954e-03, -3.8124e-02,  3.4025e-02, -3.1605e-02, -3.0506e-02,\n         1.6144e-02,  3.3461e-03,  2.9865e-02,  3.1498e-03, -8.7744e-03,\n        -7.9670e-03,  5.1293e-02,  5.2007e-02, -1.4452e-02,  4.3132e-02,\n         1.1911e-02, -6.2249e-03,  1.2040e-02, -3.0299e-02,  3.2514e-03,\n        -3.7159e-02, -2.0337e-02, -1.8121e-03,  1.1770e-02,  2.4344e-02,\n        -6.1377e-03,  4.1198e-03, -2.4536e-02, -1.0493e-01,  1.6889e-03,\n         1.9077e-02,  2.5318e-02, -5.2049e-02,  3.2210e-02,  6.6864e-02,\n         1.7774e-02,  5.1526e-02,  5.8221e-02, -1.3624e-02, -2.3117e-03,\n         2.0338e-02,  2.2427e-02, -3.0113e-02,  4.3537e-02,  1.1212e-02,\n        -3.8908e-02, -7.0008e-02,  1.3595e-02, -3.7944e-02, -1.3232e-02,\n         4.6632e-04, -1.5283e-02, -3.2783e-02,  6.0080e-03,  4.6461e-02,\n         1.8889e-02, -4.2908e-02,  9.5878e-02, -2.6894e-03, -1.7004e-02,\n        -3.4620e-02, -6.5361e-02, -7.2729e-02, -6.6933e-02, -1.0298e-02,\n         2.3286e-02, -4.1942e-02,  7.3983e-03, -5.7962e-02,  1.3872e-02,\n         3.3543e-02,  1.8002e-02, -1.4692e-02, -1.1176e-02, -1.1609e-02,\n        -6.3130e-03,  1.3969e-02,  4.3088e-02, -4.0917e-02,  3.2560e-02,\n         2.9851e-02, -1.7261e-02,  1.6777e-02, -8.6104e-03, -6.9494e-03,\n        -1.3400e-02,  1.4408e-02,  4.5058e-02,  1.0638e-02, -7.1648e-04,\n        -2.3207e-02, -1.1586e-03,  2.3797e-02, -3.8870e-02, -1.6237e-02,\n         4.8891e-02, -1.7307e-02,  9.2606e-03,  9.1270e-03, -5.4900e-02,\n         4.7433e-02,  1.1945e-01,  4.1334e-02, -5.4621e-02,  4.2962e-02,\n         8.6338e-03,  4.3706e-02, -2.4647e-02, -1.6332e-02, -2.1507e-03,\n         8.7885e-03, -2.3470e-02,  5.3824e-02,  1.4440e-02, -1.3071e-02,\n         6.3935e-03, -2.4621e-02,  2.2473e-02,  7.3544e-02, -5.4295e-02,\n         2.9795e-02, -4.0032e-02,  1.7406e-02,  1.9343e-02, -3.5376e-03,\n         3.9566e-02, -1.5670e-02, -6.2787e-02,  1.7414e-02, -2.3611e-02,\n         1.8833e-02, -1.6068e-02,  6.7016e-03,  8.4096e-03,  8.1792e-03,\n        -2.9809e-02,  3.6470e-02,  1.8595e-02,  5.6800e-03,  1.5710e-02,\n         5.9957e-03, -1.8259e-03, -5.1509e-03, -6.3660e-02,  2.8735e-02,\n         5.9676e-02, -1.3662e-02, -1.4247e-02,  4.3195e-03,  4.5108e-02,\n         3.5563e-02,  4.8292e-03, -3.6303e-02, -8.7873e-02, -3.9448e-02,\n        -2.5622e-02,  9.2024e-03,  3.5239e-02, -9.0849e-03,  2.2998e-02,\n        -2.5885e-02,  2.4638e-02, -7.4060e-03,  2.0444e-03, -2.9061e-02,\n        -5.9412e-02, -2.2228e-02,  1.0510e-02, -2.9197e-02,  6.1409e-02,\n        -2.7648e-02, -8.8238e-03, -3.1691e-02, -2.6261e-02, -5.2661e-03,\n        -9.6524e-03,  5.1910e-03, -1.6476e-02, -5.4921e-03,  3.2438e-02,\n         1.1756e-04,  2.3901e-02,  1.3358e-02,  2.5990e-02, -1.3736e-02,\n        -1.2893e-03,  2.2395e-02,  3.6601e-03, -3.2610e-02,  1.7889e-02,\n         1.6538e-02, -5.1497e-03, -5.3975e-02, -4.0199e-02, -2.2320e-02,\n         3.2143e-02, -2.7334e-03,  7.9659e-02,  3.3079e-02,  3.9423e-03,\n        -5.8130e-02, -3.5739e-02, -6.4850e-02,  2.2640e-02,  3.0109e-02,\n         1.7165e-03,  5.0946e-02, -2.3612e-02, -1.5402e-02,  1.7263e-02,\n        -1.8169e-02,  4.3776e-02, -7.8673e-03, -6.0767e-03, -1.4069e-02,\n         7.0650e-02, -6.0479e-02, -2.9545e-03,  3.8974e-02, -6.4430e-03,\n         2.7176e-02,  9.3050e-03, -3.9082e-03,  1.0707e-02, -8.2041e-02,\n         1.5652e-02,  9.4970e-03, -3.5861e-03, -4.6537e-02, -2.1108e-02,\n         5.6213e-02, -1.7410e-02,  2.4669e-02,  1.9221e-02, -3.6182e-02,\n        -6.8075e-02, -1.0878e-02,  2.4445e-02,  4.6198e-03,  3.1299e-02,\n         4.4702e-02, -6.7230e-02,  2.7006e-03, -8.3468e-03,  3.3175e-02,\n         1.2075e-02, -2.9465e-02,  3.5476e-02, -2.4328e-02,  2.3425e-02,\n        -1.3229e-02, -3.0845e-02,  1.7383e-02,  1.2100e-02, -2.5442e-02,\n        -3.8780e-02,  4.0642e-02, -2.0243e-02, -3.0593e-02, -2.8045e-02,\n         4.5691e-02,  2.9050e-02, -5.9990e-02,  2.3333e-02, -4.8856e-02,\n        -1.3050e-02,  2.8406e-02, -1.6371e-02, -4.8437e-02, -4.0449e-02,\n         6.9544e-02, -3.2419e-02,  3.7649e-02,  3.2362e-02,  3.4945e-02,\n        -7.1975e-03, -4.3289e-02,  7.2309e-03, -1.3184e-02,  4.1549e-03,\n         3.1399e-02, -8.5700e-02, -1.3846e-02, -2.4856e-02,  1.2897e-02,\n         5.4828e-03, -4.3292e-02, -2.5291e-02, -2.4888e-02,  1.8745e-03,\n         1.0606e-02, -5.1738e-02,  4.0153e-02,  3.4107e-02,  4.6542e-03,\n        -8.9991e-02,  3.1049e-02, -4.3464e-03, -1.3488e-01, -3.9131e-02,\n        -2.6635e-02, -4.2403e-02,  2.9816e-02,  3.7999e-02, -9.8345e-02,\n         2.5945e-02,  2.3479e-02, -6.2636e-02,  4.0598e-02,  4.4855e-02,\n        -4.5020e-03, -5.7073e-02,  1.6999e-02,  6.2140e-02, -6.4843e-02,\n        -1.8054e-02, -5.7143e-02, -6.5145e-02, -3.4255e-02,  7.4827e-03,\n         4.9320e-02,  2.1630e-02,  1.8153e-02,  2.2069e-02, -1.2006e-02,\n         4.4503e-02,  1.8691e-03,  4.6394e-02,  5.9513e-03,  5.6710e-02,\n        -8.5719e-02, -1.8320e-02,  3.0303e-03, -7.1369e-03,  7.6076e-02,\n        -1.5465e-02, -6.8238e-02,  1.1388e-02,  2.8199e-02,  2.2502e-02,\n        -1.8815e-03,  1.1100e-01,  7.4535e-03,  4.0027e-02, -9.9135e-03,\n         3.0187e-02,  2.4680e-02,  3.2725e-02, -2.8673e-02, -2.3811e-02,\n         5.6494e-02,  6.6119e-02,  3.0806e-03,  5.6668e-02,  7.1068e-02,\n         2.0271e-02, -1.1937e-02,  3.3966e-02,  1.5780e-02,  4.5659e-02,\n         2.2211e-02,  3.3218e-02, -1.4998e-03, -2.4728e-03,  2.5699e-02,\n         4.0644e-02, -3.3241e-02,  1.5342e-02,  1.8141e-03, -2.9224e-03,\n        -1.7276e-02,  1.6699e-02, -6.1063e-02, -7.1393e-02,  1.9692e-03,\n        -2.4503e-03,  5.1477e-02, -1.9928e-02,  2.6411e-02, -6.1675e-02,\n         8.0095e-03,  9.6429e-03, -4.7637e-03,  7.6144e-03,  4.9702e-02,\n         2.1452e-02, -1.4799e-02,  2.8665e-02, -2.5321e-02,  4.6698e-02,\n         2.6398e-02,  4.3857e-02, -8.3027e-02,  8.8499e-03, -2.5007e-02,\n         2.7256e-02,  5.9373e-02,  3.2460e-02,  1.1791e-02,  2.8699e-04,\n        -3.4254e-03, -2.4098e-02,  6.0221e-02, -2.3989e-02,  2.1157e-02,\n        -2.8588e-02,  3.5966e-02,  5.6346e-02,  4.6354e-02, -2.6744e-02,\n         1.8119e-02, -4.8258e-02,  4.1412e-03,  4.0007e-02,  4.6542e-02,\n        -6.6875e-33, -3.3084e-02,  4.6477e-02, -5.1396e-03,  6.7082e-02,\n        -3.7069e-02,  3.9685e-02,  2.5754e-03,  6.2564e-03, -4.3731e-02,\n        -7.2768e-03, -3.3438e-02,  1.6566e-02,  2.2510e-02,  2.7167e-02,\n        -1.2661e-02, -3.4842e-02,  2.0931e-02, -1.6430e-02,  2.4514e-02,\n        -1.3001e-02, -2.2256e-02,  2.8697e-02,  9.4101e-02, -1.7610e-02,\n        -6.6804e-02, -5.4179e-03,  6.4961e-03, -5.1682e-02, -4.8556e-02,\n         1.0618e-02, -2.3642e-02,  2.7785e-02, -9.8912e-03, -3.5785e-02,\n         3.6102e-03, -3.6236e-02, -3.8733e-02,  3.7712e-02, -1.9778e-02,\n         6.4426e-02, -3.6401e-02, -2.3221e-02,  5.2430e-02,  7.8321e-03,\n        -4.4609e-02, -1.9216e-03,  1.8202e-02, -1.0212e-02, -5.0738e-02,\n        -6.0177e-02, -9.9551e-03,  1.5158e-02, -2.8511e-02, -4.7128e-02,\n         2.9219e-02,  9.3907e-03, -1.1987e-02,  3.6568e-03, -7.7096e-02,\n         2.0882e-02,  2.7430e-02,  5.1224e-02,  2.1967e-02,  2.6814e-02,\n        -8.2935e-03,  1.7347e-02,  6.8111e-02,  3.0897e-03,  1.8285e-02,\n        -5.4474e-02,  3.2590e-02,  9.7911e-02,  4.2276e-02,  1.0040e-02,\n         3.7952e-02, -6.9564e-02, -2.8848e-02,  2.0187e-03, -3.3290e-02,\n        -5.9281e-03, -6.2626e-03,  3.1764e-03, -4.0040e-02, -2.0609e-02,\n        -1.8555e-03, -7.3103e-02, -1.6309e-02, -1.1785e-02,  1.3340e-02,\n         1.1396e-02,  6.0589e-03,  8.2197e-02,  2.7562e-02, -3.6221e-02,\n         7.4788e-02, -1.0773e-02, -1.5003e-02,  6.9640e-02, -4.0911e-02,\n        -3.6065e-03, -2.4918e-02, -1.2283e-02,  4.9157e-03,  5.4169e-02,\n         3.8575e-03,  2.6457e-02, -1.9470e-03,  6.1951e-02, -2.4478e-02,\n        -3.2047e-02, -1.9078e-02,  3.0714e-02,  3.0795e-02,  5.0432e-02,\n         6.4343e-02, -2.9286e-02,  5.9004e-03,  1.8874e-02, -1.6607e-02,\n        -1.4981e-02, -2.1667e-02,  4.5407e-02,  5.7364e-02,  1.2100e-02,\n         1.1678e-03,  2.3697e-02, -5.9945e-02, -7.3616e-03, -3.8959e-02,\n        -6.6105e-02, -1.7351e-02,  8.6127e-03,  2.9996e-07, -2.4863e-03,\n         3.8585e-02,  3.7582e-02, -1.5786e-02,  9.0979e-03,  2.2621e-02,\n         1.1591e-03,  1.8719e-02, -1.6076e-02, -2.8303e-02,  5.0191e-02,\n         2.7447e-03,  1.5320e-02,  7.4805e-03, -7.3240e-03, -7.8009e-02,\n        -1.8536e-02,  2.3956e-03, -1.9919e-02, -2.1212e-02,  6.3378e-02,\n         5.3246e-02, -2.6111e-02, -3.0092e-02,  4.5185e-02,  1.3558e-03,\n         6.6459e-02,  3.5620e-02,  9.3659e-03,  1.2605e-02,  7.0240e-03,\n         1.3285e-02, -7.4667e-03,  3.6396e-02, -2.0748e-02, -1.6505e-02,\n         4.6866e-02,  1.3899e-02, -7.0520e-03, -5.6238e-02,  1.9354e-02,\n         6.8173e-02, -1.2364e-02,  3.4388e-03,  6.7298e-02, -6.3852e-02,\n        -2.2644e-02, -1.4752e-02, -6.0733e-02, -1.2376e-02,  4.8465e-02,\n        -1.2148e-02,  4.3899e-03,  2.9901e-02, -8.2482e-03, -3.7173e-02,\n        -2.1249e-02, -7.0156e-02,  1.5898e-02,  6.5276e-03, -4.5774e-02,\n        -2.5208e-02, -3.1812e-02, -9.6327e-02,  1.0183e-01,  5.9741e-02,\n        -7.2997e-02,  2.6527e-34, -8.1441e-03,  2.8645e-02,  3.9208e-02,\n         3.6679e-02, -4.7427e-02, -2.8388e-02,  2.8068e-02, -2.2235e-02,\n        -1.8546e-02, -2.5114e-02, -2.6054e-02], device='cuda:0')"},"metadata":{}}]},{"cell_type":"markdown","source":"–ö—Ä—É—Ç–æ, —Ç–µ–ø–µ—Ä—å —É –Ω–∞—Å —Ç—É—Ç –¥–≤–∞ –ø–æ–¥—Ö–æ–¥–∞ –∫–∞–∫ —Ä–µ—à–∞—Ç—å –¥–∞–ª—å—à–µ –∑–∞–¥–∞—á—É\n1) –∏—Å–ø–æ–ª—å—â–æ–≤–∞—Ç—å util –∏–∑ sentence transformers\n\n2) —Ö–∞–π–ø–æ–≤—ã–π FAISS\n\n–ù—É –∞ –º—ã —á—Ç–æ, –º—ã AIKC, –º—ã –ø–æ–∫–∞–∂–µ–º –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞!","metadata":{}},{"cell_type":"markdown","source":"–î–ª—è –Ω–∞—á–∞–ª–∞ –≤–æ–∑—å–º–µ–º util","metadata":{}},{"cell_type":"code","source":"query = \"Overall Architecture of KAT?\"\n\nemb_query = emb_model.encode(query, convert_to_tensor=True).to(device)\n\ndot_scores = util.dot_score(a=emb_query, b=embeds)[0]\n\ntop_res = torch.topk(dot_scores, k=5)\n\ntop_res","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:26.913377Z","iopub.execute_input":"2024-10-30T17:02:26.913705Z","iopub.status.idle":"2024-10-30T17:02:27.034151Z","shell.execute_reply.started":"2024-10-30T17:02:26.913660Z","shell.execute_reply":"2024-10-30T17:02:27.033216Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"858d74165a0540169b203349a6a50295"}},"metadata":{}},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"torch.return_types.topk(\nvalues=tensor([0.5441, 0.5422, 0.4372, 0.3706, 0.3697], device='cuda:0'),\nindices=tensor([ 48,  73,  52, 116,  47], device='cuda:0'))"},"metadata":{}}]},{"cell_type":"code","source":"pdf_chunks_lower_than_50_tokens[48]['emb'].shape","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:27.035348Z","iopub.execute_input":"2024-10-30T17:02:27.035664Z","iopub.status.idle":"2024-10-30T17:02:27.041725Z","shell.execute_reply.started":"2024-10-30T17:02:27.035632Z","shell.execute_reply":"2024-10-30T17:02:27.040742Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"(768,)"},"metadata":{}}]},{"cell_type":"markdown","source":"–î–∞–≤–∞–π—Ç–µ –∑–∞–ø—É—Å—Ç–∏–º –º–æ–¥–µ–ª—å–∫—É","metadata":{}},{"cell_type":"code","source":"model_id = \"unsloth/gemma-2-2b-it-bnb-4bit\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,  bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.float16\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    device_map=\"auto\",\n    torch_dtype=torch.float16,\n    quantization_config=bnb_config\n)\ntokenizer = AutoTokenizer.from_pretrained(model_id)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:27.043258Z","iopub.execute_input":"2024-10-30T17:02:27.043634Z","iopub.status.idle":"2024-10-30T17:02:31.336114Z","shell.execute_reply.started":"2024-10-30T17:02:27.043591Z","shell.execute_reply":"2024-10-30T17:02:31.335132Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n/opt/conda/lib/python3.10/site-packages/transformers/quantizers/auto.py:186: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n  warnings.warn(warning_msg)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"–ù–∞–ø–∏—à–µ–º –ø—Ä–æ–º–ø—Ç –∏ –ø–æ–¥–∞–¥–∏–º –º–æ–¥–µ–ª–∏!","metadata":{}},{"cell_type":"code","source":"prompt = \"\"\"\n–ü—Ä–∏–≤–µ—Ç, —Ç—ã –ø–æ–º–æ–≥–∞–µ—à—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Ä–∞–∑–±–∏—Ä–∞—Ç—å—Å—è –≤ –∑–∞–ø—Ä–æ—Å–∞—Ö –ø–æ —Å—Ç–∞—Ç—å—è–º. –û—Ç–≤–µ—á–∞–π –Ω–∞ –µ–≥–æ –≤–æ–ø—Ä–æ—Å—ã, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç, –æ—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º. –ù–µ –ø–∏—à–∏ –∫–æ–¥, –∞ —Å–ª–æ–≤–∞–º–∏ –æ–±—ä—è—Å–Ω—è–π –∫–∞–∫ –æ–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç\n{context}\n–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n{query}\nAns:\n\n\"\"\"\n\nquery = \"What is Kolmogorov Arnold Transformer?\"\n\nemb_query = emb_model.encode(query, convert_to_tensor=True).to(device)\n\ndot_scores = util.dot_score(a=emb_query, b=embeds.to(device))[0]\n\ntop_res = torch.topk(dot_scores, k=1)\n\nmost_sim = int(top_res[1][0])\n\nprint(top_res)\n\nprompt = prompt.format(\n    context=pdf_chunks_lower_than_50_tokens[int(top_res[1][0])]['sents_chunks'],\n    query=query\n)\n\n\ndialogue_template = [\n        {\"role\": \"user\",\n         \"content\": prompt}\n    ]\n\nprompt = tokenizer.apply_chat_template(\n    conversation=dialogue_template,\n    tokenize=False,\n    add_generation_prompt=True\n)\n\ninput_ids = tokenizer(prompt, return_tensors='pt').to(device)\n\noutput_ids = model.generate(\n    **input_ids,\n    temperature=0.85,\n    do_sample=True,\n    max_new_tokens=1024\n)\n\nout_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:31.337435Z","iopub.execute_input":"2024-10-30T17:02:31.337792Z","iopub.status.idle":"2024-10-30T17:02:46.186487Z","shell.execute_reply.started":"2024-10-30T17:02:31.337758Z","shell.execute_reply":"2024-10-30T17:02:46.185649Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a5cd9a5830e466aafd706a725fcbe15"}},"metadata":{}},{"name":"stdout","text":"torch.return_types.topk(\nvalues=tensor([0.6301], device='cuda:0'),\nindices=tensor([0], device='cuda:0'))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"–û—Ç–≤–µ—Ç!","metadata":{}},{"cell_type":"code","source":"print(f\"Query: {query}\")\nprint(f\"RAG answer:\\m{out_text.replace(prompt, '')}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:02:46.187605Z","iopub.execute_input":"2024-10-30T17:02:46.187933Z","iopub.status.idle":"2024-10-30T17:02:46.192952Z","shell.execute_reply.started":"2024-10-30T17:02:46.187900Z","shell.execute_reply":"2024-10-30T17:02:46.192084Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Query: What is Kolmogorov Arnold Transformer?\nRAG answer:\\muser\n–ü—Ä–∏–≤–µ—Ç, —Ç—ã –ø–æ–º–æ–≥–∞–µ—à—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Ä–∞–∑–±–∏—Ä–∞—Ç—å—Å—è –≤ –∑–∞–ø—Ä–æ—Å–∞—Ö –ø–æ —Å—Ç–∞—Ç—å—è–º. –û—Ç–≤–µ—á–∞–π –Ω–∞ –µ–≥–æ –≤–æ–ø—Ä–æ—Å—ã, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç, –æ—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º. –ù–µ –ø–∏—à–∏ –∫–æ–¥, –∞ —Å–ª–æ–≤–∞–º–∏ –æ–±—ä—è—Å–Ω—è–π –∫–∞–∫ –æ–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç\nKolmogorov‚ÄìArnold Transformer Xingyi Yang Xinchao Wang National University of Singapore xyang@u.nus.edu; xinchao@nus.edu.sg Input Emb. Norm Attention Norm MLP Transformer Input Emb. Norm Attention Norm KAN ViT + KAN ViT KAT* DeiT ViT + KAN KAT Input Emb. Norm Attention Norm GR-KAN KAT(Ours) Figure 1: (Left) Architecture of standard transformer (e.g. ViT), ViT+KAN which substitutes the MLP with a KAN, and our KAT model. In KAT, the MLP layers in transformers are replaced with GR-KAN layers. (\n–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\nWhat is Kolmogorov Arnold Transformer?\nAns:\nmodel\nKolmogorov‚ÄìArnold Transformer - —ç—Ç–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ç–∏–ø –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π —è–≤–ª—è–µ—Ç—Å—è —É–ª—É—á—à–µ–Ω–Ω—ã–º –≤–∞—Ä–∏–∞–Ω—Ç–æ–º —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã Transformers, –Ω–∞–ø—Ä–∏–º–µ—Ä, ViT (Vision Transformer). \n\n–ì–ª–∞–≤–Ω–∞—è –∏–¥–µ—è - –∑–∞–º–µ–Ω–∏—Ç—å —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ MLP (Multi-layered perceptrons) –≤ Transformer –Ω–∞ GR-KAN (Gated Recurrent Kan). GR-KAN —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ –≤–∏–¥–µ –ø–æ—Ç–æ–∫–æ–≤.  \n\n–î—Ä—É–≥–∏–º–∏ —Å–ª–æ–≤–∞–º–∏, KOLOMAGOV-ARNOLD Transformer –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ GR-KAN –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –µ–º—É –ª—É—á—à–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –æ—Å–Ω–æ–≤–∞–Ω–Ω—É—é –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ. \n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"–¢–µ–ø–µ—Ä—å —Å–¥–µ–ª–∞–µ–º –≤—Å–µ —Å FAISS","metadata":{}},{"cell_type":"code","source":"import faiss\n\nembeds_np = embeds.cpu().numpy().astype('float32')\nfaiss.normalize_L2(embeds_np)\n\nindex = faiss.IndexFlatIP(768)\nindex.add(embeds_np)\n\nquery = \"What is Kolmogorov Arnold Transformer?\"\nemb_query = emb_model.encode(query, convert_to_tensor=True).cpu().numpy().astype('float32')\nemb_query = np.expand_dims(emb_query, axis=0)\nfaiss.normalize_L2(emb_query)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:07:31.064772Z","iopub.execute_input":"2024-10-30T17:07:31.065522Z","iopub.status.idle":"2024-10-30T17:07:31.161281Z","shell.execute_reply.started":"2024-10-30T17:07:31.065483Z","shell.execute_reply":"2024-10-30T17:07:31.160180Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fba1d34bde540e1832a65bd9d240bc6"}},"metadata":{}},{"name":"stdout","text":"(768,)\n(1, 768)\n","output_type":"stream"}]},{"cell_type":"code","source":"D, I = index.search(emb_query, 1)  # –¢–æ–ø-1 —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n\nmost_sim = int(I[0][0])\n\nprompt = \"\"\"\n–ü—Ä–∏–≤–µ—Ç, —Ç—ã –ø–æ–º–æ–≥–∞–µ—à—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Ä–∞–∑–±–∏—Ä–∞—Ç—å—Å—è –≤ –∑–∞–ø—Ä–æ—Å–∞—Ö –ø–æ —Å—Ç–∞—Ç—å—è–º. –û—Ç–≤–µ—á–∞–π –Ω–∞ –µ–≥–æ –≤–æ–ø—Ä–æ—Å—ã, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç, –æ—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º. –ù–µ –ø–∏—à–∏ –∫–æ–¥, –∞ —Å–ª–æ–≤–∞–º–∏ –æ–±—ä—è—Å–Ω—è–π –∫–∞–∫ –æ–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç.\n{context}\n–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n{query}\nAns:\n\"\"\"\n\nprompt = prompt.format(\n    context=pdf_chunks_lower_than_50_tokens[most_sim]['sents_chunks'],\n    query=query\n)\n\ndialogue_template = [\n    {\"role\": \"user\", \"content\": prompt}\n]\n\nprompt = tokenizer.apply_chat_template(\n    conversation=dialogue_template,\n    tokenize=False,\n    add_generation_prompt=True\n)\n\ninput_ids = tokenizer(prompt, return_tensors='pt').to(device)\noutput_ids = model.generate(\n    **input_ids,\n    temperature=0.85,\n    do_sample=True,\n    max_new_tokens=1024\n)\n\nout_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n\nprint(out_text)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T17:07:43.552161Z","iopub.execute_input":"2024-10-30T17:07:43.552568Z","iopub.status.idle":"2024-10-30T17:08:00.033205Z","shell.execute_reply.started":"2024-10-30T17:07:43.552527Z","shell.execute_reply":"2024-10-30T17:08:00.032196Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"user\n–ü—Ä–∏–≤–µ—Ç, —Ç—ã –ø–æ–º–æ–≥–∞–µ—à—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Ä–∞–∑–±–∏—Ä–∞—Ç—å—Å—è –≤ –∑–∞–ø—Ä–æ—Å–∞—Ö –ø–æ —Å—Ç–∞—Ç—å—è–º. –û—Ç–≤–µ—á–∞–π –Ω–∞ –µ–≥–æ –≤–æ–ø—Ä–æ—Å—ã, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç, –æ—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º. –ù–µ –ø–∏—à–∏ –∫–æ–¥, –∞ —Å–ª–æ–≤–∞–º–∏ –æ–±—ä—è—Å–Ω—è–π –∫–∞–∫ –æ–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç.\nKolmogorov‚ÄìArnold Transformer Xingyi Yang Xinchao Wang National University of Singapore xyang@u.nus.edu; xinchao@nus.edu.sg Input Emb. Norm Attention Norm MLP Transformer Input Emb. Norm Attention Norm KAN ViT + KAN ViT KAT* DeiT ViT + KAN KAT Input Emb. Norm Attention Norm GR-KAN KAT(Ours) Figure 1: (Left) Architecture of standard transformer (e.g. ViT), ViT+KAN which substitutes the MLP with a KAN, and our KAT model. In KAT, the MLP layers in transformers are replaced with GR-KAN layers. (\n–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\nWhat is Kolmogorov Arnold Transformer?\nAns:\nmodel\n\"Kolmogorov-Arnold Transformer\" - —ç—Ç–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è Xingyi Yang, Xinchao Wang.  \n\n–≠—Ç–æ –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ Transformer, –∏–∑–≤–µ—Å—Ç–Ω–æ–π –∫–∞–∫ \"ViT\".  \n\n–í–º–µ—Å—Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö MLP (Fully Connected layers) –≤ Transformer, KAT –∏—Å–ø–æ–ª—å–∑—É–µ—Ç GR-KAN (Graph-based Kernel Attention) layers, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –µ–π –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Ç–µ–∫—Å—Ç –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ. \n\n–û—Å–Ω–æ–≤–Ω—ã–µ –æ—Ç–ª–∏—á–∏—è KAT –æ—Ç ViT –∏ –¥—Ä—É–≥–∏—Ö Transformer-–º–æ–¥–µ–ª–µ–π:\n *  KAT –∏—Å–ø–æ–ª—å–∑—É–µ—Ç GR-KAN –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. \n *  KAT –º–æ–∂–µ—Ç –±—ã—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∞ –∏ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.  \n\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"–í–æ—Ç –∏ –≤–µ—Å—å RAG! –ï—Å–ª–∏ –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å—ã - –º–æ–π —Ç–≥ —è –æ—Å—Ç–∞–≤–∏–ª –≤ –Ω–∞—á–∞–ª–µ!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}